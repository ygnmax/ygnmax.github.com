<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Guangnan&#39;s Notes</title>
  
  <subtitle>I rest, I rust</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-08-13T15:53:26.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ygnmax</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Jump Process</title>
    <link href="http://yoursite.com/2020/08/15/Stochastic%20Calculus%20-%20Jump%20Process/"/>
    <id>http://yoursite.com/2020/08/15/Stochastic Calculus - Jump Process/</id>
    <published>2020-08-15T04:00:00.000Z</published>
    <updated>2020-08-13T15:53:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h1><p>Consider a jump process $X(t)$:</p><script type="math/tex; mode=display">\begin{eqnarray}X(t) &=& X(0) + I(t) + R(t) + J(t) \\&=& X^c(t) + J(t) \\ &=& X(0) + \int_{0}^{t}\Gamma(s)dW_s + \int_{0}^{t}\Theta(s)ds+J(t)\end{eqnarray}</script><p>where $X^c(t)$ is Ito process and $J(t)$ is a pure jump process</p><ul><li>no jump at time 0</li><li><p>has only finitely many jumps on each finite time interval $[0, T]$</p></li><li><p>constant between jumps</p></li><li><p>right-continuous $J(0) = 0$ and $J(t) = \lim_{s \to t^+}J(s)$ , $t \geq 0$</p></li></ul><p>The jump size is defined as $\Delta J(t) = J(t) - J(t^-)$. And $\Delta J(0) = 0 \Rightarrow J(0) = J(0^-)$, $X(0) = X(0^-)$ </p><p>If $X(t)$ is continuous at time $t$, then $\Delta X(t) = 0$. If $X(t)$ jump at time $t$, then $\Delta X(t) \neq 0$ is the size of the jump: $\Delta X(t) \neq 0$ is the size of the jump: $\Delta X(t) = J(t) - J(t^-) = \Delta J(t)$</p><p>The quadratic deviation: </p><script type="math/tex; mode=display">\begin{eqnarray}dX^c(t)dX^c(t) = \Gamma^2(t)dt \\[X^c, X^c](t) = \int_0^t\Gamma^2(s)ds\end{eqnarray}</script><p>Let $X(t)$ be a jump process defined above, and let $\Phi(s)$ be an adapted process. The stochastic integral of $\Phi(s)$ with respect to $X(t)$ is </p><script type="math/tex; mode=display">\begin{eqnarray}\label{eqn1}\int_{0}^{t}\Phi(s)dX_s = \int_{0}^{t}\Phi(s)\Gamma(s)dW_s + \int_{0}^{t}\Phi(s)\Theta(s)ds + \int_{0}^{t}\Phi(s)dJ(s)\end{eqnarray}</script><p>Because</p><script type="math/tex; mode=display">\\dX_s = \Gamma(s)dW_s+\Theta(s)ds + dJ(s)</script><p>Here, $dJ(s)$ has no definition at the jump point, but the integral $\int_{0}^{t}\Phi(s)dJ(s)$ is exactly </p><script type="math/tex; mode=display">\sum_{0 < s \leq t}\Phi(s)\Delta J(s)</script><p>Recall that </p><script type="math/tex; mode=display">I(t) = \int_{0}^{t}\Phi(s)dW_s</script><p>is a martingale $s \leq t \Rightarrow E[I(t)|F(s)] = I(s)$. Now, consider </p><script type="math/tex; mode=display">H(t) = \int_{0}^{t}\Phi(s)dX_s</script><p>where $X(s)$ is a jump process. <strong>$H(t)$ is not necessarily a martingale</strong>. For example, $X(t) = N(t) - \lambda t$, $\Phi(s) = \Delta N(s)$</p><script type="math/tex; mode=display">\int_{0}^{t}\Phi(s)dX(s) = \int_0^{t}\Phi(s)dX^c_s + \int_0^{t}\Phi(s)dJ(s)</script><p>The first part is </p><script type="math/tex; mode=display">-\lambda \int_{0}^{t} \Phi(s)ds = 0</script><p>the second part is </p><script type="math/tex; mode=display">\sum_{0<s\leq t} (\Delta N(s))^2 = \sum_{s = 0}^t 1^2 = N(t)</script><p>therefore, </p><script type="math/tex; mode=display">\int_{0}^{t}\Phi(s)dX(s) = N(t)</script><p>which is not a martingale.</p><p>Theorem: Assume that the jump process $X(s)$ is a martingale, the integrand $\Phi(s)$ is left-continuous and adapted, and $E\left[\int_0^t \Gamma^2(s)\Phi^2(s)ds\right] &lt; \infty$ for all $t \geq 0$, then</p><script type="math/tex; mode=display">\int_{0}^{t}\Phi(s)dX(s)</script><p>is also a martingale.</p><p>$\Phi(s)$ can be regarded as a position, $X(s)$ can be regarded as a price, then $\int_{0}^{t}\Phi(s)dX(s)$ can be regarded as a gain.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Definition&quot;&gt;&lt;a href=&quot;#Definition&quot; class=&quot;headerlink&quot; title=&quot;Definition&quot;&gt;&lt;/a&gt;Definition&lt;/h1&gt;&lt;p&gt;Consider a jump process $X(t)$:&lt;/p&gt;
&lt;s
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/tags/Stochastic-Calculus/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic Differential Equation1</title>
    <link href="http://yoursite.com/2020/08/14/Stochastic%20Differential%20Equation%20-%20Introdunction/"/>
    <id>http://yoursite.com/2020/08/14/Stochastic Differential Equation - Introdunction/</id>
    <published>2020-08-14T04:00:00.000Z</published>
    <updated>2021-05-29T04:38:30.629Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Source-of-Randomness"><a href="#Source-of-Randomness" class="headerlink" title="Source of Randomness"></a>Source of Randomness</h1><p>Consider an ordinary differential equation</p><script type="math/tex; mode=display">\begin{eqnarray}\begin{cases}dX(t) = a(t,X(t))dt \\X(0) = X_0\end{cases}\end{eqnarray}</script><p>There are two kinds of source of randomness if we change it to SDE: </p><ul><li><p>Randomize the initial value</p><script type="math/tex; mode=display">\begin{eqnarray}\begin{cases}dX(t) = a(t,X(t))dt \\X_0(\omega) = Y(\omega)\end{cases}\end{eqnarray}</script><p>Example:</p><script type="math/tex; mode=display">\begin{eqnarray}\begin{cases}dX_t = X_tdt \\X_0 = e^N, N\sim N(0,\sigma)\end{cases}\end{eqnarray}</script><p>The solution is </p><script type="math/tex; mode=display">X_t = X_0e^t=e^{N+t}</script><p>which is a stochastic process.</p></li><li><p>There is an additional Random Noise $B_t$</p><script type="math/tex; mode=display">dX_t = a(t,X_t)dt + b(t,X_t)dB_t</script><p>The Integral form is</p><script type="math/tex; mode=display">X_t = X_0 + \int_{0}^{t} a(s,X_s)ds + \int_{0}^{t} b(s,X_s)dB_s</script></li></ul><p>The Noise term is called driving process. If the driving process is a Brownian Motion, we call it <strong>Ito Stochastic Differential Equation (Ito SDE)</strong>. But it can be other processes, like semi-martingale, Levy process, etc. Brownian Motion is a special semi-martingale.</p><h1 id="Existence-of-Solution"><a href="#Existence-of-Solution" class="headerlink" title="Existence of Solution"></a>Existence of Solution</h1><h2 id="Strong-Solution"><a href="#Strong-Solution" class="headerlink" title="Strong Solution"></a>Strong Solution</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>A stochastic differential equation </p><script type="math/tex; mode=display">X_t = X_0 + \int_{0}^{t} a(s,X_s)ds + \int_{0}^{t} b(s,X_s)dB_s</script><p>has strong solution if the following conditions are satisfied:</p><ul><li>$X_t$ is adapted $B_t$, i.e. $X_t$ is a function of $B_s$, $s \leq t$. </li><li>$\int<em>{0}^{t} a(s,X_s)ds$ and $\int</em>{0}^{t} b(s,X_s)dB_s$ are well defined</li><li>$X_t$ is a function of the underlying sample path and of $a(t,X_t)$ and $b(t, X_t)$</li></ul><p>If we only care about the solution at the distribution level, then it is a weak solution.</p><h3 id="Lipschitz-Condition"><a href="#Lipschitz-Condition" class="headerlink" title="Lipschitz Condition"></a>Lipschitz Condition</h3><p>Assume the initial condition $X_0$ satisfying </p><ul><li><p>$\mathbb{E}[X_0^2] &lt; \infty$</p></li><li><p>independent of $B_t$, $t \geq 0$</p></li></ul><p>If $\forall t \in [0,T]$ and $x,y \in \mathbb{R}$</p><ul><li>$a(t,X_t)$, $b(t,X_t)$ are continuous</li><li>$\exists k \in [0,T]$ such that  $|a(t,X_t)-a(t,Y_t)| +|b(t,X_t)-b(t,Y_t)| \leq k|X_t-Y_t| $ </li></ul><p>Then Ito SDE has unique strong solution $S_t$ on $[0,T]$</p><p>For example</p><script type="math/tex; mode=display">X_t = X_0 + \int_{0}^{t} (c_1X_s+c_2)ds + \int_{0}^{t} (\sigma_1X_s+\sigma_2)dB_s, s \in [0,T]</script><p>then Lipschitz condition shows that </p><script type="math/tex; mode=display">|c_1||X-Y|+|\sigma_1||X-Y| \leq k|X-Y| \\k \geq |c_1| + |\sigma_1|</script><p>This linear Ito SDE has unique strong solution.</p><h1 id="Solution-of-SDE"><a href="#Solution-of-SDE" class="headerlink" title="Solution of SDE"></a>Solution of SDE</h1><h2 id="Ito-SDE"><a href="#Ito-SDE" class="headerlink" title="Ito SDE"></a>Ito SDE</h2><h3 id="Equivalent-SDE"><a href="#Equivalent-SDE" class="headerlink" title="Equivalent SDE"></a>Equivalent SDE</h3><p>Consider a SDE in two Calculus system:</p><p>In Ito Calculus</p><script type="math/tex; mode=display">dX_t = a(t,X_t)dt + b(t,X_t)dB_t</script><p>In Stratonovich Calculus</p><script type="math/tex; mode=display">dX_t = \widetilde{a}(t,X_t)dt + \widetilde{b}(t,X_t) \circ dB_t</script><p>These two SDEs should give the same solution, which means they are <strong>equivalent SDE</strong>. In practice. We need to find the relationship between $a$ and $\tilde{a}$; $b$ and $\tilde{b}$.</p><h3 id="From-Ito-to-Stratonovich"><a href="#From-Ito-to-Stratonovich" class="headerlink" title="From Ito to Stratonovich"></a>From Ito to Stratonovich</h3><p>Consider an Ito SDE</p><script type="math/tex; mode=display">X_T = X_0 + \int_{0}^{T}a(t,X_t)dt + \int_{0}^{T}b(t,X_t)dB_t</script><p>Then the transformation formula from Ito Calculus to Stratonovich Calculus is</p><script type="math/tex; mode=display">\int_{0}^{T}f(t,X_t) \circ dB_t = \int_{0}^{T}f(t,X_t)dB_t + \frac{1}{2}\int_{0}^{T}b(t,X_t)f_X(t,X_t) dt</script><blockquote><p>For example, consider an Ito SDE</p><script type="math/tex; mode=display">dX_t = dW_t \\f(t,X) = X</script><p>Here, $b(t,X_t) = 1$, $f_X(t,X) = 1$, then</p><script type="math/tex; mode=display">\begin{eqnarray}\int_{0}^{T}W_t\circ dW_t &=& \int_{0}^{T}W_tdW_t + \frac{1}{2}\int_{0}^{T}dt \\&=& \int_{0}^{T}W_tdW_t + \frac{1}{2}T \\&=& \frac{1}{2}W_t^2 - \frac{T}{2} + \frac{1}{2}T \\&=& \frac{1}{2}W_t^2\end{eqnarray}</script></blockquote><h3 id="Solve-Ito-SDE"><a href="#Solve-Ito-SDE" class="headerlink" title="Solve Ito SDE"></a>Solve Ito SDE</h3><p>Consider an Ito SDE</p><script type="math/tex; mode=display">X_T = X_0 + \int_{0}^{T}a(t,X_t)dt + \int_{0}^{T}b(t,X_t)dB_t</script><p>Because</p><script type="math/tex; mode=display">\int_{0}^{T}f(t,X_t)\circ dB_t = \int_{0}^{T}f(t,X_t)dB_t + \frac{1}{2}\int_{0}^{T}b(t,X_t)f_X(t,X_t) dt</script><p>where $\int_{0}^{T}f(t,X_t)\circ dB_t$ is Stratonovich Integral. Let $f(t,X_t) \to b(t, X_t)$</p><script type="math/tex; mode=display">\int_{0}^{T}f(t,X_t)\circ dB_t = \int_{0}^{T}b(t,X_t)\circ dB_t = \int_{0}^{T}b(t,X_t)dB_t + \frac{1}{2}\int_{0}^{T}b(t,X_t)b_X(t,X_t) dt \\\int_{0}^{T}b(t,X_t)dB_t  =  \int_{0}^{T}b(t,X_t)\circ dB_t -\frac{1}{2}\int_{0}^{T}b(t,X_t)b_X(t,X_t) dt</script><p>Therefore</p><script type="math/tex; mode=display">\begin{eqnarray}dX_t &=& a(t,X_t)dt + b(t,X_t)dB_t \\&=& a(t,X_t)dt+b(t,X_t)\circ dB_t -\frac{1}{2}b(t,X_t)b_X(t,X_t)dt \\&=& \left[a(t,X_t) - \frac{1}{2}b(t,X_t)b_X(t,X_t)\right]dt + b(t,X_t)\circ dB_t \\&=& \widetilde{a}(t,X_t)dt + \widetilde{b}(t,X_t) \circ dB_t\end{eqnarray}</script><p>We can get the relationship</p><script type="math/tex; mode=display">\begin{eqnarray}\widetilde{a}(t,X_t) &=& \left[a(t,X_t) - \frac{1}{2}b(t,X_t)b_X(t,X_t)\right] \\\widetilde{b}(t,X_t) &=& b(t,X_t)\end{eqnarray}</script><p>Then for each Stratonovich SDE, we can solve the analogue of in ODE. After getting the solution to ODE, we can derive it back to the solution of Stratonovich SDE, which is the equivalent solution to Ito SDE.</p><h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h4><p>Consider an Ito SDE</p><script type="math/tex; mode=display">dX_t = \frac{1}{2}f(X_t)f'(X_t)dt + f(X_t)dB_t</script><p>but we want to solve it in Stratonovich Calculus. We can find that</p><script type="math/tex; mode=display">\begin{eqnarray}\tilde{a} &=& \frac{1}{2}f(X_t)f'(X_t) - \frac{1}{2}f(X_t)f'(X_t) = 0 \\\tilde{b} &=& f(X_t)\end{eqnarray}</script><p>Therefore, the equivalent Stratonovich SDE is</p><script type="math/tex; mode=display">dX_t = f(X_t) \circ dB_t</script><p>Assume the original function of $\frac{1}{f(x)}$ is $g(x)$, the analogue in ODE is </p><script type="math/tex; mode=display">\begin{eqnarray}dl_t &=& f(l_t)dc_t \\\frac{dl_t}{f(l_t)} &=& dc_t \\\int_{l_0}^{l_t}\frac{du}{f(u)} &=& c_t-c_0 \\g(l_t)-g(l_0) &=& c_t - c_0 \\g(l_t) &=& g(l_0) + c_t - c_0 \\\end{eqnarray}</script><p>and we change change it back to Stratonovich SDE:</p><script type="math/tex; mode=display">\begin{eqnarray}g(X_t) &=& g(X_0) + B_t - B_0 \\X_t &=& g^{-1}(g(X_0) + B_t - B_0)\end{eqnarray}</script><p>The solution is also for Ito SDE.</p><h4 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h4><p> Solve the SDE</p><script type="math/tex; mode=display">dX_t = \frac{1}{2}nX_t^{2n-1}d_t+X_t^ndB_t</script><p>The $f(X) = X^n, \frac{1}{2}f(X)f’(X) = \frac{1}{2}X^{2n-1}$, so the equivalent SDE is</p><script type="math/tex; mode=display">dX_t = X_t^n \circ dB_t</script><p>the analogue in ODE is</p><script type="math/tex; mode=display">\begin{eqnarray}dl_t &=& l_t^ndc_t \\\frac{1}{l_t^n}dl_t &=& dc_t \\\int_{l_0}^{l_t}\frac{1}{u^n}du &=& \int_{0}^{t}dc_t \\\int_{l_0}^{l_t}\frac{1}{u^n}du &=& c_t - c_0 \\\frac{1}{1-n}u^{1-n}|_{l_0}^{l_t} &=& c_t - c_0 \\\frac{1}{1-n}(l_t)^{1-n}-\frac{1}{1-n}(l_0)^{1-n} &=& c_t - c_0\end{eqnarray}</script><p>Then transform it back to SDE</p><script type="math/tex; mode=display">\begin{eqnarray}\frac{1}{1-n}X_t^{1-n}-\frac{1}{1-n}X_0^{1-n} &=& B_t -B_0 \\X_t^{1-n} &=& B_t(1-n) + X_0^{1-n} \\X_t &=& [B_t(1-n) + X_0^{1-n}]^{\frac{1}{^{1-n}}}, n \geq 2\end{eqnarray}</script><h4 id="Example-3"><a href="#Example-3" class="headerlink" title="Example 3"></a>Example 3</h4><p>Solve the SDE</p><script type="math/tex; mode=display">dX_t = [qf(X_t)+\frac{1}{2}f(X_t)f'(X_t)]dt+f(X_t)dB_t</script><p>Here, $a(t,X_t) = qf(X_t)+\frac{1}{2}f(X_t)f’(X_t)$, $b(t,X_t)=f(X_t)$</p><p>Then </p><script type="math/tex; mode=display">\begin{eqnarray}\tilde{a}(t,X_t) &=& a(t,X_t)-\frac{1}{2}f(X)f'(X) \\&=& qf(X_t) \\\tilde{b}(t,X_t) &=& b(t,X_t)\\&=& f(X_t) \\\end{eqnarray}</script><p>Therefore, the corresponding SDE in Stratonovich is</p><script type="math/tex; mode=display">dX_t = qf(X_t)dt+f(X_t) \circ dB_t</script><p>Then find the analogue of the Stratonovich SDE in ODE</p><script type="math/tex; mode=display">\begin{eqnarray}dl_t &=& qf(l_t)dt+f(l_t)dc_t \\\frac{dl_t}{f(l_t)}  &=& qdt+dc_t \\\int_{l_0}^{l_t}\frac{du}{f(u)}  &=& qt+c_t -c_0 \\g(l_t)-g(l_0) &=& qt + c_t - c_0 \\\end{eqnarray}</script><p>And change it back to SDE</p><script type="math/tex; mode=display">\begin{eqnarray}g(X_t) &=& g(X_0) + qt + B_t - B_0 \\&=& g(X_0) + qt + B_t \\X_t &=& g^{-1}(g(X_0) + qt + B_t - B_0)\end{eqnarray}</script><h4 id="Example-4-Ornstein-Uhlenbeck-Process"><a href="#Example-4-Ornstein-Uhlenbeck-Process" class="headerlink" title="Example 4 Ornstein-Uhlenbeck Process"></a>Example 4 Ornstein-Uhlenbeck Process</h4><script type="math/tex; mode=display">X_t = X_0 + c\int_{0}^{t}X_sds + \sigma\int_{0}^{t}dB_s</script><p>$X<em>0$ is not random. It is also called <em>_Langevin Equation</em></em>. The differential form is</p><script type="math/tex; mode=display">dX_t = cX_tdt+\sigma dB_t</script><h5 id="Time-series"><a href="#Time-series" class="headerlink" title="Time-series"></a>Time-series</h5><p>If $dt$ = 1, then the Ornstein-Uhlenbeck Process become</p><script type="math/tex; mode=display">X_{t+1}-X_t = cX_t+\sigma(B_{t+1}-B_{t}) \\X_{t+1} = (c+1)X_t+\sigma(B_{t+1}-B_{t})</script><p>if we define $\phi = c+1, \epsilon<em>t = \sigma(B</em>{t+1}-B_{t}) \sim N(0,\sigma^2)$, then</p><script type="math/tex; mode=display">X_{t+1}=\phi X_t+\epsilon_t</script><p>This is Autoregressive Model with order 1.</p><h5 id="Solution-to-Ornstein-Uhlenbeck-Process"><a href="#Solution-to-Ornstein-Uhlenbeck-Process" class="headerlink" title="Solution to Ornstein-Uhlenbeck Process"></a>Solution to Ornstein-Uhlenbeck Process</h5><p>solve $dX_t = cX_tdt+\sigma dB_t$, $X_0$ is deterministic.</p><p>Step 1: Define $Y<em>t = f(t,X_t) = e^{-ct}X_t$, we can easily get $f_t = -ce^{-ct}X_t$, $f_X = e^{-ct}$, $f</em>{XX}=0$. </p><p>Step 2: According Ito formula:</p><script type="math/tex; mode=display">\begin{eqnarray}dY_t = df(t,X_t) &=& -ce^{-ct}X_tdt +  e^{-ct}dX_t + \frac{1}{2} \times0 \times dt \\&=& -ce^{-ct}X_tdt +  e^{-ct}(cX_tdt+\sigma dB_t) \\&=& -ce^{-ct}X_tdt +  e^{-ct}(cX_tdt+\sigma dB_t) \\&=& e^{-ct}\sigma dB_t\end{eqnarray}</script><blockquote><p>How to find the function like $e^{-ct}$?</p><p>Let $Y<em>t = f(t,X_t) = P_tX_t$, we can easily get $f_t = X_tP’_t$, $f_X = P_t$, $f</em>{XX}=0$, then by Ito formula</p><script type="math/tex; mode=display">\begin{eqnarray}dY_t = df(t,X_t) &=& P'_tX_tdt +  P_tdX_t + \frac{1}{2} \times0 \times dt \\&=& P'_tX_tdt +  P_t(cX_tdt+\sigma dB_t) \\&=& P'_tX_tdt +  P_t(cX_tdt+\sigma dB_t) \\&=& (P'_t + cP_t) X_tdt+ P_t\sigma dB_t\end{eqnarray}</script><p>We want to eliminate the drift term $(P’_t + cP_t) X_tdt$ because we can solve the equation only if there is no $X_t$ in the RHS. The $X_t$ can only appear in the LHS. Therefore, let $P’_t = -cP_t$, we can easily get</p><script type="math/tex; mode=display">P_t = \lambda e^{-ct}</script></blockquote><p>Step3: Integrate both sides</p><script type="math/tex; mode=display">\begin{eqnarray}\int_{0}^{t}dY_s &=& \sigma\int_{0}^{t} e^{-cs} dB_s \\Y_t -Y_0 &=& \sigma\int_{0}^{t} e^{-cs} dB_s \\e^{-ct}X_t -X_0 &=& \sigma\int_{0}^{t} e^{-cs} dB_s \\X_t &=& e^{ct}X_0 + \sigma e^{ct}\int_{0}^{t} e^{-cs} dB_s \\\end{eqnarray}</script><h3 id="General-Solution-to-Ito-SDE"><a href="#General-Solution-to-Ito-SDE" class="headerlink" title="General Solution to Ito SDE"></a>General Solution to Ito SDE</h3><p>Consider a general Ito SDE</p><script type="math/tex; mode=display">dX(u) = (a(u)+b(u)X(u))du + (\gamma(u)+\sigma(u)X(u))dW(u)</script><p>where $a(u), b(u), \gamma(u), \sigma(u)$ are adapted to $\mathcal{F(u)}$, $u \geq 0$. $\mathcal{F(u)}$ is a generated $\sigma$-algebra, which means that all the events in the Borel set can be found in $\mathcal{F(u)}$. In the finance, this means that it contains all the information at $u$.</p><p>Let</p><script type="math/tex; mode=display">\begin{eqnarray}Z(u) &=& e^{\int_{t}^{u}\sigma(v)dW(v)+\int_{t}^{u}(b(v)-\frac{1}{2}\sigma^2(v))dv} = e^{Q(u)} \\Y(u) &=& X + \int_{t}^{u}\frac{a(v)-\sigma(v)\gamma(v)}{Z(v)}dv + \int_{t}^{u}\frac{\gamma(v)}{Z(v)}dW(v)\end{eqnarray}</script><p>where $0 \leq t \leq u$.</p><p>When $Z(t) = 1$, then</p><script type="math/tex; mode=display">\begin{eqnarray}dZ(u) &=& de^{Q(u)} = e^{Q(u)}dQ(u) + \frac{1}{2}e^{Q(u)}dQ(u)dQ(u) \\&=& Z(u)[\sigma(u)dW(u)+(b(u)-\frac{1}{2}\sigma^2(u))du]+\frac{1}{2}Z(u)\sigma^2(u)du \\&=& Z(u)\sigma(u)dW(u) + Z(u)b(u)du\end{eqnarray}</script><p>which is generalized geometric Brownian Motion.</p><script type="math/tex; mode=display">\begin{eqnarray}dY(u) &=& \frac{a(u)-\sigma(u)\gamma(u)}{Z(u)}du + \frac{\gamma(u)}{Z(u)}dW(u)\end{eqnarray}</script><p>Because</p><script type="math/tex; mode=display">\begin{eqnarray}dX(u) &=& d[Y(u)Z(u)] = Z(u)dY(u) + Y(u)dZ(u) + dZ(u)dY(u) \\&=& (a(u)-\sigma(u)\gamma(u))du + \gamma(u)dW(u) \\&+& Y(u)Z(u)(\sigma(u)dW(u) +b(u)du) \\&+& \sigma(u)\gamma(u)du \\&=& (a(u)-\sigma(u)\gamma(u)+b(u)Y(u)Z(u)+\sigma(u)\gamma(u))du + (\gamma(u)+Y(u)Z(u)\sigma(u))dW(u) \\&=& (a(u)+b(u)X(u))du + (\gamma(u)+\sigma(u)X(u))dW(u) \\\end{eqnarray}</script><p>The solution is</p><script type="math/tex; mode=display">X(u) = Y(u)Z(u)</script><p>According the Lipschitz Condition, let $m(t,X) = a(t)+b(t)X(t)$, $n(t,X) = \gamma(u)+\sigma(u)X(u)$, then solve the inequity:</p><script type="math/tex; mode=display">\begin{eqnarray}|m(t,X)-m(t,Y)|+|n(t,X)-n(t,Y)| &\leq& k|X-Y| \\|b(t)+\sigma(t)||X-Y| &\leq& k|X-Y| \\|b(t)+\sigma(t)| &\leq& k\end{eqnarray}</script><p>In $0 \leq t \leq T$, $b(t)$ and $\sigma(t)$ should be bounded.</p><p>Therefore, the solution is the unique strong solution.</p><h2 id="Feynman-Kac-Formula"><a href="#Feynman-Kac-Formula" class="headerlink" title="Feynman-Kac Formula"></a>Feynman-Kac Formula</h2><h2 id="Monte-Carlo"><a href="#Monte-Carlo" class="headerlink" title="Monte Carlo"></a>Monte Carlo</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Source-of-Randomness&quot;&gt;&lt;a href=&quot;#Source-of-Randomness&quot; class=&quot;headerlink&quot; title=&quot;Source of Randomness&quot;&gt;&lt;/a&gt;Source of Randomness&lt;/h1&gt;&lt;
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/tags/Stochastic-Calculus/"/>
    
      <category term="Stochastic Differential Equation" scheme="http://yoursite.com/tags/Stochastic-Differential-Equation/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic Differential Equation</title>
    <link href="http://yoursite.com/2020/08/14/Stochastic%20Calculus%20-%20Stochastic%20Differential%20Equation/"/>
    <id>http://yoursite.com/2020/08/14/Stochastic Calculus - Stochastic Differential Equation/</id>
    <published>2020-08-14T04:00:00.000Z</published>
    <updated>2020-08-13T15:15:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Source-of-Randomness"><a href="#Source-of-Randomness" class="headerlink" title="Source of Randomness"></a>Source of Randomness</h1><p>Consider an ordinary differential equation</p><script type="math/tex; mode=display">\begin{eqnarray}\begin{cases}dX(t) = a(t,X(t))dt \\X(0) = X_0\end{cases}\end{eqnarray}</script><p>There are two kinds of source of randomness if we change it to SDE: </p><ul><li><p>Randomize the initial value</p><script type="math/tex; mode=display">\begin{eqnarray}\begin{cases}dX(t) = a(t,X(t))dt \\X_0(\omega) = Y(\omega)\end{cases}\end{eqnarray}</script><p>Example:</p><script type="math/tex; mode=display">\begin{eqnarray}\begin{cases}dX_t = X_tdt \\X_0 = e^N, N\sim N(0,\sigma)\end{cases}\end{eqnarray}</script><p>The solution is </p><script type="math/tex; mode=display">X_t = X_0e^t=e^{N+t}</script><p>which is a stochastic process.</p></li><li><p>There is an additional Random Noise $B_t$</p><script type="math/tex; mode=display">dX_t = a(t,X_t)dt + b(t,X_t)dB_t</script><p>The Integral form is</p><script type="math/tex; mode=display">X_t = X_0 + \int_{0}^{t} a(s,X_s)ds + \int_{0}^{t} b(s,X_s)dB_s</script></li></ul><p>The Noise term is called driving process. If the driving process is a Brownian Motion, we call it <strong>Ito Stochastic Differential Equation (Ito SDE)</strong>. But it can be other processes, like semi-martingale, Levy process, etc. Brownian Motion is a special semi-martingale.</p><h1 id="Existence-of-Solution"><a href="#Existence-of-Solution" class="headerlink" title="Existence of Solution"></a>Existence of Solution</h1><h2 id="Strong-Solution"><a href="#Strong-Solution" class="headerlink" title="Strong Solution"></a>Strong Solution</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>A stochastic differential equation </p><script type="math/tex; mode=display">X_t = X_0 + \int_{0}^{t} a(s,X_s)ds + \int_{0}^{t} b(s,X_s)dB_s</script><p>has strong solution if the following conditions are satisfied:</p><ul><li>$X_t$ is adapted $B_t$, i.e. $X_t$ is a function of $B_s$, $s \leq t$. </li><li>$\int<em>{0}^{t} a(s,X_s)ds$ and $\int</em>{0}^{t} b(s,X_s)dB_s$ are well defined</li><li>$X_t$ is a function of the underlying sample path and of $a(t,X_t)$ and $b(t, X_t)$</li></ul><p>If we only care about the solution at the distribution level, then it is a weak solution.</p><h3 id="Lipschitz-Condition"><a href="#Lipschitz-Condition" class="headerlink" title="Lipschitz Condition"></a>Lipschitz Condition</h3><p>Assume the initial condition $X_0$ satisfying </p><ul><li><p>$\mathbb{E}[X_0^2] &lt; \infty$</p></li><li><p>independent of $B_t$, $t \geq 0$</p></li></ul><p>If $\forall t \in [0,T]$ and $x,y \in \mathbb{R}$</p><ul><li>$a(t,X_t)$, $b(t,X_t)$ are continuous</li><li>$\exists k \in [0,T]$ such that  $|a(t,X_t)-a(t,Y_t)| +|b(t,X_t)-b(t,Y_t)| \leq k|X_t-Y_t| $ </li></ul><p>Then Ito SDE has unique strong solution $S_t$ on $[0,T]$</p><p>For example</p><script type="math/tex; mode=display">X_t = X_0 + \int_{0}^{t} (c_1X_s+c_2)ds + \int_{0}^{t} (\sigma_1X_s+\sigma_2)dB_s, s \in [0,T]</script><p>then Lipschitz condition shows that </p><script type="math/tex; mode=display">|c_1||X-Y|+|\sigma_1||X-Y| \leq k|X-Y| \\k \geq |c_1| + |\sigma_1|</script><p>This linear Ito SDE has unique strong solution.</p><h1 id="Solution-of-SDE"><a href="#Solution-of-SDE" class="headerlink" title="Solution of SDE"></a>Solution of SDE</h1><h2 id="Ito-SDE"><a href="#Ito-SDE" class="headerlink" title="Ito SDE"></a>Ito SDE</h2><h3 id="Equivalent-SDE"><a href="#Equivalent-SDE" class="headerlink" title="Equivalent SDE"></a>Equivalent SDE</h3><p>Consider a SDE in two Calculus system:</p><p>In Ito Calculus</p><script type="math/tex; mode=display">dX_t = a(t,X_t)dt + b(t,X_t)dB_t</script><p>In Stratonovich Calculus</p><script type="math/tex; mode=display">dX_t = \widetilde{a}(t,X_t)dt + \widetilde{b}(t,X_t) \circ dB_t</script><p>These two SDEs should give the same solution, which means they are <strong>equivalent SDE</strong>. In practice. We need to find the relationship between $a$ and $\tilde{a}$; $b$ and $\tilde{b}$.</p><h3 id="From-Ito-to-Stratonovich"><a href="#From-Ito-to-Stratonovich" class="headerlink" title="From Ito to Stratonovich"></a>From Ito to Stratonovich</h3><p>Consider an Ito SDE</p><script type="math/tex; mode=display">X_T = X_0 + \int_{0}^{T}a(t,X_t)dt + \int_{0}^{T}b(t,X_t)dB_t</script><p>Then the transformation formula from Ito Calculus to Stratonovich Calculus is</p><script type="math/tex; mode=display">\int_{0}^{T}f(t,X_t) \circ dB_t = \int_{0}^{T}f(t,X_t)dB_t + \frac{1}{2}\int_{0}^{T}b(t,X_t)f_X(t,X_t) dt</script><blockquote><p>For example, consider an Ito SDE</p><script type="math/tex; mode=display">dX_t = dW_t \\f(t,X) = X</script><p>Here, $b(t,X_t) = 1$, $f_X(t,X) = 1$, then</p><script type="math/tex; mode=display">\begin{eqnarray}\int_{0}^{T}W_t\circ dW_t &=& \int_{0}^{T}W_tdW_t + \frac{1}{2}\int_{0}^{T}dt \\&=& \int_{0}^{T}W_tdW_t + \frac{1}{2}T \\&=& \frac{1}{2}W_t^2 - \frac{T}{2} + \frac{1}{2}T \\&=& \frac{1}{2}W_t^2\end{eqnarray}</script></blockquote><h3 id="Solve-Ito-SDE"><a href="#Solve-Ito-SDE" class="headerlink" title="Solve Ito SDE"></a>Solve Ito SDE</h3><p>Consider an Ito SDE</p><script type="math/tex; mode=display">X_T = X_0 + \int_{0}^{T}a(t,X_t)dt + \int_{0}^{T}b(t,X_t)dB_t</script><p>Because</p><script type="math/tex; mode=display">\int_{0}^{T}f(t,X_t)\circ dB_t = \int_{0}^{T}f(t,X_t)dB_t + \frac{1}{2}\int_{0}^{T}b(t,X_t)f_X(t,X_t) dt</script><p>where $\int_{0}^{T}f(t,X_t)\circ dB_t$ is Stratonovich Integral. Let $f(t,X_t) \to b(t, X_t)$</p><script type="math/tex; mode=display">\int_{0}^{T}f(t,X_t)\circ dB_t = \int_{0}^{T}b(t,X_t)\circ dB_t = \int_{0}^{T}b(t,X_t)dB_t + \frac{1}{2}\int_{0}^{T}b(t,X_t)b_X(t,X_t) dt \\\int_{0}^{T}b(t,X_t)dB_t  =  \int_{0}^{T}b(t,X_t)\circ dB_t -\frac{1}{2}\int_{0}^{T}b(t,X_t)b_X(t,X_t) dt</script><p>Therefore</p><script type="math/tex; mode=display">\begin{eqnarray}dX_t &=& a(t,X_t)dt + b(t,X_t)dB_t \\&=& a(t,X_t)dt+b(t,X_t)\circ dB_t -\frac{1}{2}b(t,X_t)b_X(t,X_t)dt \\&=& \left[a(t,X_t) - \frac{1}{2}b(t,X_t)b_X(t,X_t)\right]dt + b(t,X_t)\circ dB_t \\&=& \widetilde{a}(t,X_t)dt + \widetilde{b}(t,X_t) \circ dB_t\end{eqnarray}</script><p>We can get the relationship</p><script type="math/tex; mode=display">\begin{eqnarray}\widetilde{a}(t,X_t) &=& \left[a(t,X_t) - \frac{1}{2}b(t,X_t)b_X(t,X_t)\right] \\\widetilde{b}(t,X_t) &=& b(t,X_t)\end{eqnarray}</script><p>Then for each Stratonovich SDE, we can solve the analogue of in ODE. After getting the solution to ODE, we can derive it back to the solution of Stratonovich SDE, which is the equivalent solution to Ito SDE.</p><h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h4><p>Consider an Ito SDE</p><script type="math/tex; mode=display">dX_t = \frac{1}{2}f(X_t)f'(X_t)dt + f(X_t)dB_t</script><p>but we want to solve it in Stratonovich Calculus. We can find that</p><script type="math/tex; mode=display">\begin{eqnarray}\tilde{a} &=& \frac{1}{2}f(X_t)f'(X_t) - \frac{1}{2}f(X_t)f'(X_t) = 0 \\\tilde{b} &=& f(X_t)\end{eqnarray}</script><p>Therefore, the equivalent Stratonovich SDE is</p><script type="math/tex; mode=display">dX_t = f(X_t) \circ dB_t</script><p>Assume the original function of $\frac{1}{f(x)}$ is $g(x)$, the analogue in ODE is </p><script type="math/tex; mode=display">\begin{eqnarray}dl_t &=& f(l_t)dc_t \\\frac{dl_t}{f(l_t)} &=& dc_t \\\int_{l_0}^{l_t}\frac{du}{f(u)} &=& c_t-c_0 \\g(l_t)-g(l_0) &=& c_t - c_0 \\g(l_t) &=& g(l_0) + c_t - c_0 \\\end{eqnarray}</script><p>and we change change it back to Stratonovich SDE:</p><script type="math/tex; mode=display">\begin{eqnarray}g(X_t) &=& g(X_0) + B_t - B_0 \\X_t &=& g^{-1}(g(X_0) + B_t - B_0)\end{eqnarray}</script><p>The solution is also for Ito SDE.</p><h4 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h4><p> Solve the SDE</p><script type="math/tex; mode=display">dX_t = \frac{1}{2}nX_t^{2n-1}d_t+X_t^ndB_t</script><p>The $f(X) = X^n, \frac{1}{2}f(X)f’(X) = \frac{1}{2}X^{2n-1}$, so the equivalent SDE is</p><script type="math/tex; mode=display">dX_t = X_t^n \circ dB_t</script><p>the analogue in ODE is</p><script type="math/tex; mode=display">\begin{eqnarray}dl_t &=& l_t^ndc_t \\\frac{1}{l_t^n}dl_t &=& dc_t \\\int_{l_0}^{l_t}\frac{1}{u^n}du &=& \int_{0}^{t}dc_t \\\int_{l_0}^{l_t}\frac{1}{u^n}du &=& c_t - c_0 \\\frac{1}{1-n}u^{1-n}|_{l_0}^{l_t} &=& c_t - c_0 \\\frac{1}{1-n}(l_t)^{1-n}-\frac{1}{1-n}(l_0)^{1-n} &=& c_t - c_0\end{eqnarray}</script><p>Then transform it back to SDE</p><script type="math/tex; mode=display">\begin{eqnarray}\frac{1}{1-n}X_t^{1-n}-\frac{1}{1-n}X_0^{1-n} &=& B_t -B_0 \\X_t^{1-n} &=& B_t(1-n) + X_0^{1-n} \\X_t &=& [B_t(1-n) + X_0^{1-n}]^{\frac{1}{^{1-n}}}, n \geq 2\end{eqnarray}</script><h4 id="Example-3"><a href="#Example-3" class="headerlink" title="Example 3"></a>Example 3</h4><p>Solve the SDE</p><script type="math/tex; mode=display">dX_t = [qf(X_t)+\frac{1}{2}f(X_t)f'(X_t)]dt+f(X_t)dB_t</script><p>Here, $a(t,X_t) = qf(X_t)+\frac{1}{2}f(X_t)f’(X_t)$, $b(t,X_t)=f(X_t)$</p><p>Then </p><script type="math/tex; mode=display">\begin{eqnarray}\tilde{a}(t,X_t) &=& a(t,X_t)-\frac{1}{2}f(X)f'(X) \\&=& qf(X_t) \\\tilde{b}(t,X_t) &=& b(t,X_t)\\&=& f(X_t) \\\end{eqnarray}</script><p>Therefore, the corresponding SDE in Stratonovich is</p><script type="math/tex; mode=display">dX_t = qf(X_t)dt+f(X_t) \circ dB_t</script><p>Then find the analogue of the Stratonovich SDE in ODE</p><script type="math/tex; mode=display">\begin{eqnarray}dl_t &=& qf(l_t)dt+f(l_t)dc_t \\\frac{dl_t}{f(l_t)}  &=& qdt+dc_t \\\int_{l_0}^{l_t}\frac{du}{f(u)}  &=& qt+c_t -c_0 \\g(l_t)-g(l_0) &=& qt + c_t - c_0 \\\end{eqnarray}</script><p>And change it back to SDE</p><script type="math/tex; mode=display">\begin{eqnarray}g(X_t) &=& g(X_0) + qt + B_t - B_0 \\&=& g(X_0) + qt + B_t \\X_t &=& g^{-1}(g(X_0) + qt + B_t - B_0)\end{eqnarray}</script><h4 id="Example-4-Ornstein-Uhlenbeck-Process"><a href="#Example-4-Ornstein-Uhlenbeck-Process" class="headerlink" title="Example 4 Ornstein-Uhlenbeck Process"></a>Example 4 Ornstein-Uhlenbeck Process</h4><script type="math/tex; mode=display">X_t = X_0 + c\int_{0}^{t}X_sds + \sigma\int_{0}^{t}dB_s</script><p>$X<em>0$ is not random. It is also called <em>_Langevin Equation</em></em>. The differential form is</p><script type="math/tex; mode=display">dX_t = cX_tdt+\sigma dB_t</script><h5 id="Time-series"><a href="#Time-series" class="headerlink" title="Time-series"></a>Time-series</h5><p>If $dt$ = 1, then the Ornstein-Uhlenbeck Process become</p><script type="math/tex; mode=display">X_{t+1}-X_t = cX_t+\sigma(B_{t+1}-B_{t}) \\X_{t+1} = (c+1)X_t+\sigma(B_{t+1}-B_{t})</script><p>if we define $\phi = c+1, \epsilon<em>t = \sigma(B</em>{t+1}-B_{t}) \sim N(0,\sigma^2)$, then</p><script type="math/tex; mode=display">X_{t+1}=\phi X_t+\epsilon_t</script><p>This is Autoregressive Model with order 1.</p><h5 id="Solution-to-Ornstein-Uhlenbeck-Process"><a href="#Solution-to-Ornstein-Uhlenbeck-Process" class="headerlink" title="Solution to Ornstein-Uhlenbeck Process"></a>Solution to Ornstein-Uhlenbeck Process</h5><p>solve $dX_t = cX_tdt+\sigma dB_t$, $X_0$ is deterministic.</p><p>Step 1: Define $Y<em>t = f(t,X_t) = e^{-ct}X_t$, we can easily get $f_t = -ce^{-ct}X_t$, $f_X = e^{-ct}$, $f</em>{XX}=0$. </p><p>Step 2: According Ito formula:</p><script type="math/tex; mode=display">\begin{eqnarray}dY_t = df(t,X_t) &=& -ce^{-ct}X_tdt +  e^{-ct}dX_t + \frac{1}{2} \times0 \times dt \\&=& -ce^{-ct}X_tdt +  e^{-ct}(cX_tdt+\sigma dB_t) \\&=& -ce^{-ct}X_tdt +  e^{-ct}(cX_tdt+\sigma dB_t) \\&=& e^{-ct}\sigma dB_t\end{eqnarray}</script><blockquote><p>How to find the function like $e^{-ct}$?</p><p>Let $Y<em>t = f(t,X_t) = P_tX_t$, we can easily get $f_t = X_tP’_t$, $f_X = P_t$, $f</em>{XX}=0$, then by Ito formula</p><script type="math/tex; mode=display">\begin{eqnarray}dY_t = df(t,X_t) &=& P'_tX_tdt +  P_tdX_t + \frac{1}{2} \times0 \times dt \\&=& P'_tX_tdt +  P_t(cX_tdt+\sigma dB_t) \\&=& P'_tX_tdt +  P_t(cX_tdt+\sigma dB_t) \\&=& (P'_t + cP_t) X_tdt+ P_t\sigma dB_t\end{eqnarray}</script><p>We want to eliminate the drift term $(P’_t + cP_t) X_tdt$ because we can solve the equation only if there is no $X_t$ in the RHS. The $X_t$ can only appear in the LHS. Therefore, let $P’_t = -cP_t$, we can easily get</p><script type="math/tex; mode=display">P_t = \lambda e^{-ct}</script></blockquote><p>Step3: Integrate both sides</p><script type="math/tex; mode=display">\begin{eqnarray}\int_{0}^{t}dY_s &=& \sigma\int_{0}^{t} e^{-cs} dB_s \\Y_t -Y_0 &=& \sigma\int_{0}^{t} e^{-cs} dB_s \\e^{-ct}X_t -X_0 &=& \sigma\int_{0}^{t} e^{-cs} dB_s \\X_t &=& e^{ct}X_0 + \sigma e^{ct}\int_{0}^{t} e^{-cs} dB_s \\\end{eqnarray}</script><h3 id="General-Solution-to-Ito-SDE"><a href="#General-Solution-to-Ito-SDE" class="headerlink" title="General Solution to Ito SDE"></a>General Solution to Ito SDE</h3><p>Consider a general Ito SDE</p><script type="math/tex; mode=display">dX(u) = (a(u)+b(u)X(u))du + (\gamma(u)+\sigma(u)X(u))dW(u)</script><p>where $a(u), b(u), \gamma(u), \sigma(u)$ are adapted to $\mathcal{F(u)}$, $u \geq 0$. $\mathcal{F(u)}$ is a generated $\sigma$-algebra, which means that all the events in the Borel set can be found in $\mathcal{F(u)}$. In the finance, this means that it contains all the information at $u$.</p><p>Let</p><script type="math/tex; mode=display">\begin{eqnarray}Z(u) &=& e^{\int_{t}^{u}\sigma(v)dW(v)+\int_{t}^{u}(b(v)-\frac{1}{2}\sigma^2(v))dv} = e^{Q(u)} \\Y(u) &=& X + \int_{t}^{u}\frac{a(v)-\sigma(v)\gamma(v)}{Z(v)}dv + \int_{t}^{u}\frac{\gamma(v)}{Z(v)}dW(v)\end{eqnarray}</script><p>where $0 \leq t \leq u$.</p><p>When $Z(t) = 1$, then</p><script type="math/tex; mode=display">\begin{eqnarray}dZ(u) &=& de^{Q(u)} = e^{Q(u)}dQ(u) + \frac{1}{2}e^{Q(u)}dQ(u)dQ(u) \\&=& Z(u)[\sigma(u)dW(u)+(b(u)-\frac{1}{2}\sigma^2(u))du]+\frac{1}{2}Z(u)\sigma^2(u)du \\&=& Z(u)\sigma(u)dW(u) + Z(u)b(u)du\end{eqnarray}</script><p>which is generalized geometric Brownian Motion.</p><script type="math/tex; mode=display">\begin{eqnarray}dY(u) &=& \frac{a(u)-\sigma(u)\gamma(u)}{Z(u)}du + \frac{\gamma(u)}{Z(u)}dW(u)\end{eqnarray}</script><p>Because</p><script type="math/tex; mode=display">\begin{eqnarray}dX(u) &=& d[Y(u)Z(u)] = Z(u)dY(u) + Y(u)dZ(u) + dZ(u)dY(u) \\&=& (a(u)-\sigma(u)\gamma(u))du + \gamma(u)dW(u) \\&+& Y(u)Z(u)(\sigma(u)dW(u) +b(u)du) \\&+& \sigma(u)\gamma(u)du \\&=& (a(u)-\sigma(u)\gamma(u)+b(u)Y(u)Z(u)+\sigma(u)\gamma(u))du + (\gamma(u)+Y(u)Z(u)\sigma(u))dW(u) \\&=& (a(u)+b(u)X(u))du + (\gamma(u)+\sigma(u)X(u))dW(u) \\\end{eqnarray}</script><p>The solution is</p><script type="math/tex; mode=display">X(u) = Y(u)Z(u)</script><p>According the Lipschitz Condition, let $m(t,X) = a(t)+b(t)X(t)$, $n(t,X) = \gamma(u)+\sigma(u)X(u)$, then solve the inequity:</p><script type="math/tex; mode=display">\begin{eqnarray}|m(t,X)-m(t,Y)|+|n(t,X)-n(t,Y)| &\leq& k|X-Y| \\|b(t)+\sigma(t)||X-Y| &\leq& k|X-Y| \\|b(t)+\sigma(t)| &\leq& k\end{eqnarray}</script><p>In $0 \leq t \leq T$, $b(t)$ and $\sigma(t)$ should be bounded.</p><p>Therefore, the solution is the unique strong solution.</p><h2 id="Feynman-Kac-Formula"><a href="#Feynman-Kac-Formula" class="headerlink" title="Feynman-Kac Formula"></a>Feynman-Kac Formula</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Source-of-Randomness&quot;&gt;&lt;a href=&quot;#Source-of-Randomness&quot; class=&quot;headerlink&quot; title=&quot;Source of Randomness&quot;&gt;&lt;/a&gt;Source of Randomness&lt;/h1&gt;&lt;
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/tags/Stochastic-Calculus/"/>
    
      <category term="Stochastic Differential Equation" scheme="http://yoursite.com/tags/Stochastic-Differential-Equation/"/>
    
  </entry>
  
  <entry>
    <title>Change of Probability Measure</title>
    <link href="http://yoursite.com/2020/08/13/Stochastic%20Calculus%20-%20Change%20of%20Probability%20Measure/"/>
    <id>http://yoursite.com/2020/08/13/Stochastic Calculus - Change of Probability Measure/</id>
    <published>2020-08-13T04:00:00.000Z</published>
    <updated>2020-08-13T17:43:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Probability-Measure-Change"><a href="#Probability-Measure-Change" class="headerlink" title="Probability Measure Change"></a>Probability Measure Change</h1><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><div class="table-container"><table><thead><tr><th></th><th>$\mathbb{P(\omega)}$</th><th>$\mathbb{Q(\omega)}$</th><th>$\frac{\mathbb{Q(\omega)}}{\mathbb{P(\omega)}} = Z(\omega)$</th></tr></thead><tbody><tr><td>$\omega_1$</td><td>$\frac{1}{3}$</td><td>$\frac{1}{6}$</td><td>$\frac{1}{2}$</td></tr><tr><td>$\omega_2$</td><td>$\frac{1}{3}$</td><td>$\frac{1}{12}$</td><td>$\frac{1}{4}$</td></tr><tr><td>$\omega_3$</td><td>$\frac{1}{3}$</td><td>$\frac{3}{4}$</td><td>$\frac{9}{4}$</td></tr><tr><td>sum</td><td>$1$</td><td>$1$</td></tr></tbody></table></div><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}^{\mathbb{P}}[Z(\omega)] &=& \sum_{k=1}^{3}Z(\omega_k)\mathbb{P}(\omega_k) \\&=& \frac{1}{2} \times \frac{1}{3} + \frac{1}{4} \times \frac{1}{3} + \frac{9}{4} \times \frac{1}{3} \\&=& 1\end{eqnarray}</script><p>Consider a random variable $X(\omega) \geq 0$, $X(\omega_k) = X_k, k \in {1,2,3}$</p><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}^\mathbb{Q}[X] &=& X_1 \times \frac{1}{6} + X_2 \times \frac{1}{12} + X_3 \times\frac{3}{4} \\\mathbb{E}^\mathbb{P}[XZ] &=&  \frac{1}{3} \times X_1 \times \frac{1}{2} + \frac{1}{3} \times X_2 \times \frac{1}{4} + \frac{1}{3} \times X_3 \times\frac{9}{4}\end{eqnarray}</script><p>We have $\mathbb{E}^\mathbb{Q}[X] = \mathbb{E}^\mathbb{P}[XZ]$. If $Z &gt; 0$, then $\mathbb{E}^\mathbb{P}[X] = \mathbb{E}^\mathbb{Q}\left[\frac{X}{Z}\right]$.</p><h2 id="Equivalent-Probability-Measure"><a href="#Equivalent-Probability-Measure" class="headerlink" title="Equivalent Probability Measure"></a>Equivalent Probability Measure</h2><p>Two probability measures $\mathbb{P}$ and $\mathbb{Q}$ are defined on $(\Omega, \mathscr{F})$.  $\mathbb{P}$ and $\mathbb{Q}$ are said to be equivalent if they agree which sets in $\mathscr{F}$ have probability zero.</p><h2 id="Radon–Nikodym-Derivative"><a href="#Radon–Nikodym-Derivative" class="headerlink" title="Radon–Nikodym Derivative"></a>Radon–Nikodym Derivative</h2><h3 id="Definition-amp-Theorem"><a href="#Definition-amp-Theorem" class="headerlink" title="Definition &amp; Theorem"></a>Definition &amp; Theorem</h3><p>Let $(\Omega,\mathscr{F},\mathbb{P})$ be a probability space. Let $Z(\omega) \geq 0$ almost sure, with $\mathbb{E}^{\mathbb{P}}[Z(\omega)] = 1$. For $A \in \mathscr{F}$, define $\mathbb{Q}(A) = \int<em>{A}Z(\omega)\mathbb{P}(\omega)$. If $Z(\omega)$ is discrete, then $\mathbb{Q}(A) = \sum\limits</em>{\omega \in A}Z(\omega)\mathbb{P}(\omega)$. Then $\mathbb{Q}$ is a probability measure. </p><p>If $X(\omega) \geq 0$, then </p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{Q}}[X] = \mathbb{E}^{\mathbb{P}}[XZ]</script><p>If $ Z(\omega) \geq 0$, then </p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{P}}[X] = \mathbb{E}^{\mathbb{Q}}\left[\frac{X}{Z}\right]</script><p>The $Z(w)$ is called <strong>Radon–Nikodym derivative</strong>. And $Z(\omega)$ denotes </p><script type="math/tex; mode=display">Z(\omega) = \frac{d\mathbb{Q(\omega)}}{d\mathbb{P(\omega)}}</script><p>Note that to change the probability measure, we require the condition  $\mathbb{E}^{\mathbb{P}}[Z(\omega)] = 1$. If we want to change other kind of measure, the expectation don’t have to be 1.</p><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><ol><li><p><strong>Uniform Distribution</strong></p><p>$\Omega = [0,1], A = [a,b] \in \mathscr{F},  0 \leq a \leq b \leq 1$, </p></li></ol><ul><li><p>a uniform measure $\mathbb{P}([a,b]) = b-a$, $P([0,1]) = 1$</p></li><li><p>a new measure $\mathbb{Q}([a,b]) = b^2-a^2$, $Q([0,1]) = 1$ </p><p>Then</p></li></ul><script type="math/tex; mode=display">Z(\omega) = \frac{d\mathbb{Q(\omega)}}{d\mathbb{P(\omega)}} = \frac{\mathbb{Q}([\omega, \omega+\Delta\omega])}{\mathbb{P}([\omega, \omega+\Delta\omega])} = \frac{(\omega+\Delta\omega)^2 - \omega^2}{\omega+\Delta\omega - \omega} = 2\omega+\Delta\omega</script><p>​        if the small interval is going to 0, we get</p><script type="math/tex; mode=display">Z(\omega) = \frac{d\mathbb{Q(\omega)}}{d\mathbb{P(\omega)}}  = 2\omega</script><p>​    <strong>2. Normal Distribution</strong></p><ul><li><p>Under an original measure $\mathbb{P}$, an normal random variable $ Y \sim N^{\mathbb{P}}(\theta,1)$</p></li><li><p>find a new measure $\mathbb{Q}$,  $Y \sim N^{\mathbb{Q}}(0,1)$</p><blockquote><p>About the standard normal distribution, the pdf is</p><script type="math/tex; mode=display">\phi(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}, x \in \mathbb{R}</script><p>the cdf is</p><script type="math/tex; mode=display">\Phi(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi}}e^{-\frac{s^2}{2}}ds</script></blockquote><p><strong>Step 1:</strong> Under the probability space $(\Omega=\mathbb{R}, \mathscr{F}, \mathbb{P})$,  where events $\omega$ are real numbers, $\omega \sim N(0,1)$. Consider a standard normal random variable $X(\omega) = \omega \sim N(0,1)$,</p><script type="math/tex; mode=display">\begin{eqnarray}\Delta \mathbb{P}(l) &=& \mathbb{P}(l \leq \omega \leq l+\Delta l) \\&=& \mathbb{\Phi}(l+\Delta l) - \mathbb{\Phi}(l) \tag{1}\end{eqnarray}</script><p><strong>Step 2:</strong> The original random variable $Y(\omega)$ can be regarded as  $Y(\omega) = X(\omega) + \theta = \omega + \theta$ under $\mathbb{P}$.</p><p><strong>Step 3:</strong> Under $\mathbb{Q},~ Y \sim N^{\mathbb{Q}}(0,1)$, consider</p><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{Q}(l \leq Y(\omega) \leq l+\Delta l) &=& \mathbb{\Phi}(l+\Delta l) - \mathbb{\Phi}(l) \\\mathbb{Q}(l \leq \omega+\theta \leq l+\Delta l) &=& \mathbb{\Phi}(l+\Delta l) - \mathbb{\Phi}(l) \\\mathbb{Q}(l-\theta \leq \omega \leq l+\Delta l-\theta ) &=& \mathbb{\Phi}(l+\Delta l) - \mathbb{\Phi}(l) \\\end{eqnarray}</script><p> Here, $l$ can be any number. </p><p><strong>Step 4:</strong> We change $l \to l+\theta$ and get</p><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{Q}(l \leq \omega \leq l+\Delta l ) &=& \mathbb{\Phi}(l+\theta+\Delta l) - \mathbb{\Phi}(l+\theta) \\\Delta\mathbb{Q}(l) &=& \mathbb{\Phi}(l+\theta+\Delta l) - \mathbb{\Phi}(l+\theta) \tag{2}\end{eqnarray}</script><p><strong>Step 5:</strong> do the calculation</p><script type="math/tex; mode=display">\begin{eqnarray}Z(l) &=& \frac{d\mathbb{Q}}{d\mathbb{P}}(l) = \lim_{\Delta l \to 0}\frac{\Delta \mathbb{Q}}{\Delta \mathbb{P}} \\&=&  \lim_{\Delta l \to 0}\frac{\mathbb{\Phi}(l+\theta+\Delta l) - \mathbb{\Phi}(l+\theta)}{\mathbb{\Phi}(l+\Delta l) - \mathbb{\Phi}(l)} \\&=&  \lim_{\Delta l \to 0}\frac{\mathbb{\phi}(l+\theta+\Delta l) }{\mathbb{\phi}(l+\Delta l)} \\&=&  \frac{\mathbb{\phi}(l+\theta) }{\mathbb{\phi}(l)} \\Z(\omega) &=& \frac{\mathbb{\phi}(\omega+\theta) }{\mathbb{\phi}(\omega)} \\&=& \frac{\frac{1}{\sqrt{2\pi}}e^{-\frac{(\omega+\theta) ^2}{2}}}{\frac{1}{\sqrt{2\pi}}e^{-\frac{\omega^2}{2}}} \\&=& e^{-\frac{(\omega+\theta) ^2}{2}+\frac{\omega^2}{2}} \\&=& e^{-\frac{\theta^2}{2}-\omega\theta} \\&=& e^{-\frac{\theta^2}{2}-X(\omega)\theta} \\\end{eqnarray}</script><p>This is an exponential martingale. </p></li></ul><h1 id="Novikov-Condition"><a href="#Novikov-Condition" class="headerlink" title="Novikov Condition"></a>Novikov Condition</h1><p>A process $\Theta$ satisfies the Novikov Condition if </p><script type="math/tex; mode=display">\mathbb{E}\left[ e^{\frac{1}{2}\int_{0}^{T}\Theta_s^2ds}\right] < \infty</script><p>and if Novikov Condition is satisfied, then the process $M^{\Theta}$ defined as</p><script type="math/tex; mode=display">M_t^{\Theta} = e^{-\int_{0}^{t}\Theta_sdX_s - \frac{1}{2}\int_{0}^{t}\Theta^2_sds}, t \in [0,T]</script><p>is a martingale.</p><h1 id="Girsanov’s-Theorem"><a href="#Girsanov’s-Theorem" class="headerlink" title="Girsanov’s Theorem"></a>Girsanov’s Theorem</h1><h2 id="Radon–Nikodym-Derivative-process"><a href="#Radon–Nikodym-Derivative-process" class="headerlink" title="Radon–Nikodym Derivative process"></a>Radon–Nikodym Derivative process</h2><p>$Z(t) = \mathbb{E}[Z|\mathcal{F}(t)]$, $0\leq t \leq T$. We consider it as a Radon–Nikodym Derivative process.</p><ul><li>$Z(t)$ is a martingale</li></ul><blockquote><p>Two ways to prove martingale:</p><ol><li>$ \mathbb{E}[W(t)|\mathcal{F}(s)] = W(s)$</li><li>$dX(t) = a(t,X(t))dW(t)$</li></ol></blockquote><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[Z(t)|\mathcal{F}(s)] &=& \mathbb{E}[\mathbb{E}[Z|\mathcal{F}(t)]|\mathcal{F(s)}] \\&=& \mathbb{E}[Z|\mathcal{F}(s)]\end{eqnarray}</script><ul><li><p>$Z(\omega)$ is a Radon–Nikodym Derivative, we have</p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{Q}}[Y] = \mathbb{E}^{\mathbb{P}}[YZ]</script><p>If $Y$ is $\mathcal{F}(t)$-measurable, then</p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{Q}}[Y] = \mathbb{E}^{\mathbb{P}}[YZ(t)] \\</script></li><li><p>If If $Y$ is $\mathcal{F}(t)$-measurable, $0 \leq s \leq t \leq T$, then</p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{Q}}[Y|\mathcal{F}(s)] = \frac{1}{Z(s)}\mathbb{E}^{\mathbb{P}}[YZ(t)|\mathcal{F}(s)]</script><p><strong>proof:</strong></p><p>Both $Z(s)$ and $\mathbb{E}^{\mathbb{P}}[YZ(t)|\mathcal{F}(s)]$ are $\mathcal{F}(s)$-measurable. We want to show that it is consistent with the definition of conditional expectation. Therefore, for any $A \in \mathcal{F(s)}$, we have</p><script type="math/tex; mode=display">\begin{eqnarray}\int_{\Omega} \mathbb{I}_{A}(\omega) \frac{1}{Z(s)}\mathbb{E}^{\mathbb{P}}[YZ(t)|\mathcal{F}(s)]d\mathbb{Q}(\omega) &=& \mathbb{E}^{\mathbb{Q}}\left[ \mathbb{I}_{A}(\omega) \frac{1}{Z(s)}\mathbb{E}^{\mathbb{P}}[YZ(t)|\mathcal{F}(s)]\right] \\&=& \mathbb{E}^{\mathbb{P}}\left[ \mathbb{I}_{A}(\omega)\mathbb{E}^{\mathbb{P}}[YZ(t)|\mathcal{F}(s)]\right] \\&=& \mathbb{E}^{\mathbb{P}}\left[ \mathbb{E}^{\mathbb{P}}[\mathbb{I}_{A}(\omega)YZ(t)|\mathcal{F}(s)]\right] \\&=& \mathbb{E}^{\mathbb{P}}\left[\mathbb{I}_{A}(\omega)YZ(t)\right] \\&=& \mathbb{E}^{\mathbb{Q}}\left[\mathbb{I}_{A}(\omega)Y\right] \\&=& \int_{\Omega} \mathbb{I}_{A}(\omega) Y(\omega)d\mathbb{Q}(\omega) \\&=& \int_{A} Y(\omega)d\mathbb{Q}(\omega) \\\end{eqnarray}</script></li><li></li></ul><h2 id="Girsanov’s-Theorem-in-Finance"><a href="#Girsanov’s-Theorem-in-Finance" class="headerlink" title="Girsanov’s Theorem in Finance"></a>Girsanov’s Theorem in Finance</h2><p>Let $W(t)$ be a Brownian Motion on $(\Omega, \mathcal{F}, \mathbb{P})$ and let $\mathcal{F}$ be a filtration for the Brownian Motion. Let $\Theta(t)$ be an adapted process and satisfied the <em>Novikov Condition</em>. Define</p><script type="math/tex; mode=display">Z(t) = e^{-\int_{0}^{t}\Theta(u)dW(u)-\frac{1}{2}\int_{0}^{t}\Theta^2(u)du} \\\widetilde{W}(t) = W(t) + \int_{0}^{t}\Theta(u)du</script><p>Set $Z = Z(T)$, then $\mathbb{E}Z = 1, Z \geq 0$, and under $\mathbb{Q}$ given by</p><script type="math/tex; mode=display">\mathbb{Q}(A) = \int_{A}Z(\omega)d\mathbb{P}(\omega), \forall A \in \mathcal{F}</script><p>the process $\widetilde{W}(t)$ is a Brownian Motion.</p><p><strong>Proof</strong></p><p>Step 1 : prove Z(t) can be a Radon–Nikodym derivative, which means that we need to show the expectation $\mathbb{E}Z = 1$. </p><p>1.1 We want to prove that $Z(t)$ is a martingale:</p><script type="math/tex; mode=display">\begin{eqnarray}Z(t) &=& e^{-\int_{0}^{t}\Theta(u)dW(u)-\frac{1}{2}\int_{0}^{t}\Theta^2(u)du} = e^{X(t)} \\dZ(t) &=&  e^{X(t)}dX(t) + \frac{1}{2} e^{X}dX(t)dX(t) \\&=&Z(t)[-\Theta(t)dW(t)-\frac{1}{2}\Theta^2(t)dt] + \frac{1}{2}Z(t)\Theta^2(t)dt \\&=&-Z(t)\Theta(t)dW(t)\end{eqnarray}</script><p>Therefore, $Z(t)$ is a $\mathbb{P}$-martingale. $Z(t)= Z(0)+\int_{0}^{t}\Theta(u)Z(u)dW(u)$. </p><p>1.2 And we can verify the expectation</p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{P}}[Z] =\mathbb{E}^{\mathbb{P}}[Z(T)] = \mathbb{E}^{\mathbb{P}}[Z(T)|\mathcal{F}(0)] = Z(0) = 1</script><p>Step 2: prove  $\widetilde{W}(t)$ is a Brownian Motion. We need use the Levy’ theorem to show $\widetilde{W}(t)$ is a Brownian Motion.</p><ul><li><p>Initial Value:</p><script type="math/tex; mode=display">\widetilde{W}(0) = W(0) + \int_{0}^{0}\Theta(u)du = 0</script></li><li><p>Continuous: obvious</p></li><li><p>Quadratic Variation:</p><p>Because</p><script type="math/tex; mode=display">\widetilde{W}(t) = W(t) + \int_{0}^{t}\Theta(u)du \\d\widetilde{W}(t) = dW(t) + \Theta(t)dt</script><p>only $dW(t)$ can accumulate variation. Therefore </p><script type="math/tex; mode=display">[\widetilde{W}, \widetilde{W}](t) = [{W}, {W}](t) = t</script></li><li><p>Martingale: we want to show that $\mathbb{E}^{\mathbb{Q}}[\widetilde{W}(t)|\mathcal{F(s)}] = \widetilde{W}(s)$</p><p>For $0 \leq s \leq t \leq T$</p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{Q}}[\widetilde{W}(t)|\mathcal{F(s)}] = \frac{1}{Z(s)}\mathbb{E}^{\mathbb{P}}[\widetilde{W}(t)Z(t)|\mathcal{F}(s)]</script><p>Because</p><script type="math/tex; mode=display">\begin{eqnarray}d\widetilde{W}(t)Z(t) &=& Z(t)d\widetilde{W}(t) + \widetilde{W}(t)dZ(t) + dZ(t)d\widetilde{W}(t) \\&=& Z(t)[dW(t) + \Theta(t)dt]+ \widetilde{W}(t)[-Z(t)\Theta(t)dW(t)] + [-Z(t)\Theta(t)dW(t)][dW(t) + \Theta(t)dt] \\&=& Z(t)(1-\widetilde{W}(t)\Theta(t))dW(t)\end{eqnarray}</script><p>$\widetilde{W}(t)Z(t)$ is a $\mathbb{P}$-martingale. We have</p><script type="math/tex; mode=display">\mathbb{E}^{\mathbb{Q}}[\widetilde{W}(t)|\mathcal{F(s)}] = \frac{1}{Z(s)}\mathbb{E}^{\mathbb{P}}[\widetilde{W}(t)Z(t)|\mathcal{F}(s)] = \frac{1}{Z(s)}[\widetilde{W}(s)Z(s)] = \widetilde{W}(s)</script><p>And $\widetilde{W}(t)$ is a $\mathbb{Q}$-martingale.</p></li></ul><h2 id="Giranov’s-Theorem-in-General"><a href="#Giranov’s-Theorem-in-General" class="headerlink" title="Giranov’s Theorem in General"></a>Giranov’s Theorem in General</h2><p>Consider a SDE </p><script type="math/tex; mode=display">dX_t = f(X_t)dt + \sigma(X_t)dW_t</script><p>Let $f^<em>(X)$ be a new drift function. Assume $\frac{f^</em>(X)-f(X)}{\sigma(X)}$ is bounded. Define the measure $P^*$ by </p><script type="math/tex; mode=display">\frac{d\mathbb{P}^*}{d\mathbb{P}}(\omega)|_{\mathcal{F_t}} = e^{\int_{0}^{t}\frac{f^*(X_u)-f(X_u)}{\sigma(X_u)}dW(u)-\frac{1}{2}\int_{0}^{t}(\frac{f^*(X_u)-f(X_u)}{\sigma(X_u)})^2(u)du}</script><p>Then $\mathbb{P}^<em>$ is equivalent to $\mathbb{P}$. Moreover, the process $W^</em>$_t </p><script type="math/tex; mode=display">dW^*_t = -\frac{f^*(X_t)-f(X_t)}{\sigma(X_t)}dt+dW_t</script><p>is a Brownian Motion under $\mathbb{P}^*$ and </p><script type="math/tex; mode=display">dX_t = f^*(X_t)dt + \sigma(X_t)dW^*_t</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Probability-Measure-Change&quot;&gt;&lt;a href=&quot;#Probability-Measure-Change&quot; class=&quot;headerlink&quot; title=&quot;Probability Measure Change&quot;&gt;&lt;/a&gt;Probabil
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/tags/Stochastic-Calculus/"/>
    
  </entry>
  
  <entry>
    <title>Ito Doeblin Formula</title>
    <link href="http://yoursite.com/2020/08/12/Stochastic%20Calculus%20-%20Ito%20Doeblin%20Formula/"/>
    <id>http://yoursite.com/2020/08/12/Stochastic Calculus - Ito Doeblin Formula/</id>
    <published>2020-08-12T04:00:00.000Z</published>
    <updated>2020-08-13T02:48:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Why-do-we-need-Ito-Doeblin-Formula"><a href="#Why-do-we-need-Ito-Doeblin-Formula" class="headerlink" title="Why do we need Ito Doeblin Formula"></a>Why do we need Ito Doeblin Formula</h2><p>For ordinary calculus</p><script type="math/tex; mode=display">\frac{d}{dt}f(W(t)) = f'(W(t))W'(t) \\df(W(t)) = f'(W(t))dW(t)</script><p>but for stochastic calculus, $dW(t)$ has no definition, the formula should be revised.</p><h2 id="Ito-Doeblin-formula-for-Brownian-Motion"><a href="#Ito-Doeblin-formula-for-Brownian-Motion" class="headerlink" title="Ito Doeblin formula for Brownian Motion"></a>Ito Doeblin formula for Brownian Motion</h2><p>Let $f(t,X)$ be a function for which the partial derivatives $f<em>t(t,X)$ $f_X(t,X)$, $f</em>{XX}(t, X)$ are defined and continuous. $W(t)$ is Brownian Motion. Then for every $T \geq 0$, we have</p><script type="math/tex; mode=display">f(t, W(t)) = f(0,W(0)) + \int_{0}^{T}f_t(t,W(t))dt + \int_{0}^{T}f_X(t,W(t))dW(t) + \frac{1}{2} \int_{0}^{T}f_{XX}(t,W(t))dt</script><ul><li><p>proof</p><p>Because the Taylor Formula is</p><script type="math/tex; mode=display">f(t_{j+1},X_{j+1}) - f(t_{j},X_{j}) = f_t(t_{j},X_{j})(t_{j+1}-t_j) + f_X(t_{j},X_{j})(X_{j+1}-X_j) + \frac{1}{2}f_{tt}(t_{j},X_{j})(t_{j+1}-t_{j})^2 +  \frac{1}{2}f_{XX}(t_{j},X_{j})(X_{j+1}-X_{j})^2 + \frac{1}{2}f_{tX}(t_{j},X_{j})(t_{j+1}-t_{j})(X_{j+1}-X_{j}) o((t_{j+1}-t_j)^2) + o((X_{j+1}-X_j)^2)</script><p>Now consider a partition $\pi = {t_0, t_1, \cdots, t_n}$, $0 = t_0 &lt; t_1 &lt; \cdots &lt; t_n =T$,</p><script type="math/tex; mode=display">\begin{eqnarray}\sum_{j=0}^{n-1}f(t_{j+1},W_{j+1}) - f(t_{j},W_{j}) &=& \sum_{j=0}^{n-1}f_t(t_{j},W_{j})(t_{j+1}-t_j) \\&+& \sum_{j=0}^{n-1}f_X(t_{j},W_{j})(W_{j+1}-W_j) \\&+& \sum_{j=0}^{n-1}\frac{1}{2}f_{tt}(t_{j},W_{j})(t_{j+1}-t_{j})^2 \\&+& \sum_{j=0}^{n-1}\frac{1}{2}f_{XX}(t_{j},W_{j})(W_{j+1}-W_{j})^2 \\&+& \sum_{j=0}^{n-1}\frac{1}{2}f_{tX}(t_{j},W_{j})(W_{j+1}-W_{j})(t_{j+1}-t_{j})\end{eqnarray}</script><p>And take the limit as the max difference in partition $\pi$ goes to 0:</p><script type="math/tex; mode=display">\begin{eqnarray}\lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}f(t_{j+1},W_{j+1}) - f(t_{j},W_{j}) &=& \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}f_t(t_{j},W_{j})(t_{j+1}-t_j) \\&+& \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}f_X(t_{j},W_{j})(W_{j+1}-W_j) \\&+& \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}\frac{1}{2}f_{tt}(t_{j},W_{j})(t_{j+1}-t_{j})^2 \\&+& \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}\frac{1}{2}f_{XX}(t_{j},W_{j})(W_{j+1}-W_{j})^2 \\&+& \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}\frac{1}{2}f_{tX}(t_{j},W_{j})(W_{j+1}-W_{j})(t_{j+1}-t_{j})\end{eqnarray}</script></li></ul><p>Consider $\lim\limits<em>{||\pi|| \to 0}\sum\limits</em>{j=0}^{n-1}\frac{1}{2}f<em>{tX}(t</em>{j},W<em>{j})(W</em>{j+1}-w<em>{j})(t</em>{j+1}-t_{j})$, function $f$ </p><script type="math/tex; mode=display">\begin{eqnarray}\lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}\frac{1}{2}f_{tX}(t_{j},W_{j})(W_{j+1}-w_{j})(t_{j+1}-t_{j}) &\leq& \lim_{||\pi|| \to 0}\max_{0 \leq j \leq n-1}(t_{j+1}-t_{j})\sum_{j=0}^{n-1}\frac{1}{2}f_{tX}(t_{j},W_{j})(W_{j+1}-W_{j}) \\&=& \frac{1}{2} \cdot 0 \cdot \left|\int_{0}^{T}f_{tX}(t,W(t))dW(t)\right| = 0\end{eqnarray}</script><ul><li><p>Example</p><p>consider a function $f(t,X(t)) = \frac{1}{2}W(t)^2$, then $f<em>t(t,X(t)) = 0$,  $f_X(t,X(t)) = W(t)$,  $f</em>{XX}(t,X(t)) = 1$, apply the Ito formula</p><script type="math/tex; mode=display">df(t,X(t)) = W(t)dW(t) + \frac{1}{2}dt</script><p>and integral is</p><script type="math/tex; mode=display">f(t,X(t)) - f(t,X(0)) = \int_{0}^{t}W(s)dW(s)+\frac{1}{2}\int_{0}^{t}ds \\\frac{1}{2}W(t)^2 = \int_{0}^{t}W(s)dW(s)+\frac{1}{2}t \\\int_{0}^{t}W(s)dW(s) = \frac{1}{2}W(t)^2-\frac{1}{2}t</script></li></ul><h2 id="Ito-Process"><a href="#Ito-Process" class="headerlink" title="Ito Process"></a>Ito Process</h2><p>Define Ito Process as</p><script type="math/tex; mode=display">X(t) = X(0) + \int_{0}^{t}\Delta(u)dW(u) + \int_{0}^{t}\Theta(u)du</script><p>$X(0)$ is non-random, $\Delta(u)$, $\Theta(u)$ are adapted process of $\mathscr{F_u}$, $0 \leq u \leq T$ where $\mathscr{F_u}$ is a filtration associated with $W(u)$. The differential form is</p><script type="math/tex; mode=display">dX(t) = \Theta(t)dt + \Delta(t)dW(t)</script><h3 id="Quadratic-Variation"><a href="#Quadratic-Variation" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h3><script type="math/tex; mode=display">\left[X,X\right](t) = \int_{0}^{t}\Delta^2(u)du \\dX(t)dX(t) = \Delta^2(t)dt</script><h3 id="Integral-on-the-Ito-Process"><a href="#Integral-on-the-Ito-Process" class="headerlink" title="Integral on the Ito Process"></a>Integral on the Ito Process</h3><p>Consider an Ito Process $dX(t) = \Theta(t)dt + \Delta(t)dW(t)$</p><script type="math/tex; mode=display">\begin{eqnarray}\int_{0}^{t}\Gamma(u)dX(u) &=& \int_{0}^{t}\Gamma(u)[\Delta(u)dW(u)+\Theta(u)du] \\&=& \int_{0}^{t}\Gamma(u)\Delta(u)dW(u) + \int_{0}^{t}\Gamma(u)\Theta(u)du\end{eqnarray}</script><h2 id="Ito-Doeblin-formula-for-Ito-Process"><a href="#Ito-Doeblin-formula-for-Ito-Process" class="headerlink" title="Ito Doeblin formula for Ito Process"></a>Ito Doeblin formula for Ito Process</h2><h3 id="One-Dimension"><a href="#One-Dimension" class="headerlink" title="One Dimension"></a>One Dimension</h3><p>Consider an Ito process $dX(t) = \Theta(t)dt + \Delta(t)dW(t)$</p><script type="math/tex; mode=display">\begin{eqnarray}f(T,X(T)) &=&  f(0,X(0)) + \int_{0}^{T}f_t(t,X(t))dt + \int_{0}^{T}f_X(t,X(t))dX(t) + \frac{1}{2}\int_{0}^{T}f_{XX}(t,X(t))dX(t)dX(t) \\&=& f(0,X(0)) + \int_{0}^{T}f_t(t,X(t))dt + \int_{0}^{T}f_X(t,X(t))[\Theta(t)dt + \Delta(t)dW(t)] + \frac{1}{2}\int_{0}^{T}f_{XX}(t,X(t))\Delta^2(t)dt \\&=& f(0,X(0)) + \int_{0}^{T}[f_t(t,X(t)) + f_X(t,X(t))\Theta(t) + \frac{1}{2}f_{XX}(t,X(t))\Delta^2(t)]dt + \int_{0}^{T}f_X(t,X(t))\Delta(t)dW(t)\\\end{eqnarray}</script><h3 id="Two-Dimensions"><a href="#Two-Dimensions" class="headerlink" title="Two Dimensions"></a>Two Dimensions</h3><p>Consider two Ito processes  $dX(t) = \Theta_1(t)dt + \Delta_1(t)dW(t)$,  $dY(t) = \Theta_2(t)dt + \Delta_2(t)dW(t)$</p><script type="math/tex; mode=display">\begin{eqnarray}df(t,X(t),Y(t)) &=& f_t(t,X(t),Y(t))dt + f_X(t,X(t),Y(t))dX(t) + f_Y(t,Y(t),Y(t))dY(t) \\&+& \frac{1}{2}f_{XX}(t,X(t),Y(t))dX(t)dX(t) + \frac{1}{2}f_{YY}(t,X(t),Y(t))dY(t)dY(t) +f_{XY}(t,X(t),Y(t))dX(t)dY(t)\end{eqnarray}</script><h3 id="Ito-Production-Rule"><a href="#Ito-Production-Rule" class="headerlink" title="Ito Production Rule"></a>Ito Production Rule</h3><p>Consider the production of two Ito processes $f = X(t)Y(t)$</p><script type="math/tex; mode=display">\begin{eqnarray}df(t,X(t),Y(t)) &=& Y(t)dX(t) + X(t)dY(t) + dX(t)dY(t)\end{eqnarray}</script><p>which is different from the ordinary calculus:</p><script type="math/tex; mode=display">d(uv) = udv + vdu</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Why-do-we-need-Ito-Doeblin-Formula&quot;&gt;&lt;a href=&quot;#Why-do-we-need-Ito-Doeblin-Formula&quot; class=&quot;headerlink&quot; title=&quot;Why do we need Ito Doebl
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/tags/Stochastic-Calculus/"/>
    
  </entry>
  
  <entry>
    <title>Ito Integral</title>
    <link href="http://yoursite.com/2020/08/12/Stochastic%20Calculus%20-%20Ito%20Integral/"/>
    <id>http://yoursite.com/2020/08/12/Stochastic Calculus - Ito Integral/</id>
    <published>2020-08-12T04:00:00.000Z</published>
    <updated>2020-08-13T14:34:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ito-Integral"><a href="#Ito-Integral" class="headerlink" title="Ito Integral"></a>Ito Integral</h1><h2 id="Why-do-we-need-Ito-Integral"><a href="#Why-do-we-need-Ito-Integral" class="headerlink" title="Why do we need Ito Integral"></a>Why do we need Ito Integral</h2><p>$\int<em>{0}^{T}\Delta(t)dg(t) = \int</em>{0}^{T}\Delta(t)g’(t)dt$, but it is not true if we replace $g(t)$ with a Brownian Motion $W(t)$ because $W(t)$ has no derivative:</p><script type="math/tex; mode=display">\int_{0}^{T}\Delta(t)dW(t)</script><p>Here, $\Delta(t)$ is $\mathscr{F_t}$-measurable (which is an adapted process). In finance, $\Delta(t)$ is position, $W(t)$ is asset price, and then the integral is a gain during $[0,T]$.</p><h2 id="Ito-Integral-for-simple-function"><a href="#Ito-Integral-for-simple-function" class="headerlink" title="Ito Integral for simple function"></a>Ito Integral for simple function</h2><p>Consider an Integral $I(t) = \int_{0}^{t}\Delta(s)dW(s)$, if $\Delta(s)$ is simple function, then</p><ul><li><p>$0 \leq t \leq t_1$: </p><script type="math/tex; mode=display">I(t) = \int_0^{t}\Delta(s)dW(s) = \Delta(0)\int_0^{t}dW(s) = \Delta(0)(W(t)-W(0))</script></li><li><p>$t_1 \leq t \leq t_2$: </p><script type="math/tex; mode=display">I(t)= \int_0^{t}\Delta(s)dW(s) = \Delta(0)(W(t_1)-W(0)) + \Delta(t_1)(W(t)-W(t_1))</script></li><li><p>$t<em>k \leq t \leq t</em>{k+1}$:</p><script type="math/tex; mode=display">I(t)= \int_0^{t}\Delta(s)dW(s) = \sum_{j=0}^{k-1}\Delta(t_j)(W(t_{j+1})-W(t_j)) + \Delta(t_k)[W(t)-W(t_k)]</script></li></ul><h3 id="Martingale"><a href="#Martingale" class="headerlink" title="Martingale"></a>Martingale</h3><p>$0 \leq s \leq t \leq T, \mathbb{E}[I(t)|\mathscr{F_s}] = I(s)$</p><ul><li><p>proof: </p><p>Assume $t<em>l \leq s \leq t</em>{l+1} \leq t<em>k \leq t &lt; t</em>{k+1}$,</p><script type="math/tex; mode=display">\begin{eqnarray}I(t) &=& \sum_{j=0}^{k-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})]+\Delta(t_k)[W(t)-W(t_k)] \\&=& \sum_{j=0}^{l-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})]+\Delta(t_l)[W(t_{l+1})-W(t_{l})]+\sum_{j=l+1}^{k-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})]+\Delta(t_k)[W(t)-W(t_k)] \\&=& A_1 + A_2 + A_4 + A_4\end{eqnarray}</script><p>Then</p><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[A_1|\mathscr{F_s}] &=& A_1 = \sum_{j=0}^{l-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})] \\\mathbb{E}[A_2|\mathscr{F_s}] &=& \mathbb{E}[\Delta(t_l)(W(t_{l+1})-W(t_{l}))|\mathscr{F_s}] \\&=& \Delta(t_l)(\mathbb{E}[W(t_{l+1})|\mathscr{F_s}] - W(t_l)) \\&=& \Delta(t_l)[W(s) - W(t_l)] \\\mathbb{E}[A_3|\mathscr{F_s}] &=& \mathbb{E}\left[\mathbb{E}\left[\sum_{j=l+1}^{k-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})]|\mathscr{F_{t_j}}\right]|\mathscr{F_s}\right] \text{where $t_j \geq s $} \\&=& \mathbb{E}\left[\Delta(t_j)\left[\sum_{j=l+1}^{k-1}\mathbb{E}[W(t_{j+1})|\mathscr{F_{t_j}}]-\mathbb{E}[W(t_{j})|\mathscr{F_{t_j}}]\right]|\mathscr{F_s}\right] \\&=& \mathbb{E}\left[\Delta(t_j)\left[\sum_{j=l+1}^{k-1}\mathbb{E}[W(t_{j})]-\mathbb{E}[W(t_{j})]\right]|\mathscr{F_s}\right] = 0 \\\mathbb{E}[A_4|\mathscr{F_s}] &=& \mathbb{E}[\Delta(t_k)(W(t)-W(t_k))|\mathscr{F_s}] \\&=& \mathbb{E}[\mathbb{E}[\Delta(t_k)(W(t_{t}) - W(t_k))|\mathscr{F_{t_{k}}}]|\mathscr{F_s}] \\&=& \mathbb{E}[\Delta(t_k)(\mathbb{E}[W(t_{t})|\mathscr{F_{t_k}}] - W(t_k))|\mathscr{F_s}] \\&=& 0\end{eqnarray}</script><p>Therefore, </p></li></ul><script type="math/tex; mode=display">\mathbb{E}[I(t)|\mathscr{F_s}] = \mathbb{E}[A_1 + A_2|\mathscr{F_s}] =  \sum_{j=0}^{l-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})] + \Delta(t_l)[W(s) - W(t_l)] = I(s)</script><h3 id="Moment"><a href="#Moment" class="headerlink" title="Moment"></a>Moment</h3><ul><li><p>When $s = 0$, $\mathbb{E}[I(t)|\mathscr{F_s}] = I(0) = 0$. Therefore, we have $\mathbb{E}[I(t)] = 0$ for all $t \geq 0$ </p></li><li><p><strong>Ito Isometry</strong>: $\mathbb{Var}[I(t)] = \mathbb{E}[I^2(t)] - \mathbb{E}[I(t)]^2 = \mathbb{E}[I^2(t)] = \mathbb{E}[\int_{0}^{t}\Delta^2(u)du]$</p><ul><li>Proof:<script type="math/tex; mode=display">I(t) = \sum_{j=0}^{k-1}\Delta(t_j)[W(t_{j+1})-W(t_{j})]+\Delta(t_k)[W(t)-W(t_k)]</script>For $0 \leq j \leq k-1$, let $w(t_{j+1})-w(t_j) = D_j$ and $w(t)-w(t_k) = D_k$, then<script type="math/tex; mode=display">\begin{eqnarray}I(t) &=& \sum_{j=0}^{k}\Delta(t_j)D_j \\I^2(t) &=& \sum_{j=0}^{k}\Delta(t_j)^2D_j^2 + 2 \sum_{0 \leq i \leq j \leq k}\Delta(t_i)\Delta(t_j)D_iD_j \\\end{eqnarray}</script>Here, $\Delta(t<em>i), \Delta(t_j), D_i$ are adapted to $\mathscr{F</em>{t<em>j}}$ ($\mathscr{F</em>{t<em>j}}$-measurable), but $D_j$ is $\mathscr{F</em>{t_{j+1}}}$-measurable. In addition, they are independent increments. And $ are\Delta(t_i), \Delta(t_j)$ are finite.<script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[\Delta(t_i)\Delta(t_j)D_iD_j] &=& \mathbb{E}[\Delta(t_i)\Delta(t_j)D_i]\mathbb{E}[D_j] = 0 \\\end{eqnarray}</script>Because<script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[\Delta^2(t_j)D_j^2] &=& \mathbb{E}[\Delta^2(t_j)]\mathbb{E}[D_j^2] \\\mathbb{E}[D_j^2] &=&  \mathbb{E}[D_j^2] + \mathbb{E}^2[D_j] ~~~\text{where $D_j \sim N(0,t_{j+1}-t_j)$} \\&=& \mathbb{Var}[D_j] = t_{j+1} - t_j\end{eqnarray}</script>and $\Delta(t)$ is a simple integrand, which means that $\Delta^2(t_j)$ is a constant, we get<script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[\Delta^2(t_j)D_j^2] &=& \mathbb{E}[\Delta^2(t_j)](t_{j+1} - t_j) \\&=& \begin{cases}\int_{t_j}^{t_{j+1}}\mathbb{E}[\Delta^2(u)]du ~~~ (0 \leq j \leq k-1) \\\int_{t_k}^{t}\mathbb{E}[\Delta^2(u)]du ~~~ (j = k) \\\end{cases}\end{eqnarray}</script>Therefore, the Ito Isometry (Variance) is<script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[I^2(t)] &=& \mathbb{E}\left[\sum_{j=0}^{k}\Delta^2(t_j)(t_{j+1} - t_j)\right] \\&=& \sum_{j=0}^{k-1}\int_{t_j}^{t_{j+1}}\mathbb{E}[\Delta^2(u)]du + \int_{t_k}^{t}\mathbb{E}[\Delta^2(u)]du  \\&=& \mathbb{E}\left[\int_{0}^{t}\Delta^2(u)du \right] \end{eqnarray}</script><strong>Ito Isometry is a constant (expectation).</strong></li></ul></li></ul><h3 id="Quadratic-Variation"><a href="#Quadratic-Variation" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h3><script type="math/tex; mode=display">[I,I](t) = \int_{0}^{t}\Delta^2(u)du \\dI(t)dI(t) = \Delta^2(t)dt</script><ul><li><p>proof</p><p>In $[t<em>j,t</em>{j+1}]$ and $[t<em>k,t]$, $t_j = s_0&lt;s_1&lt;\cdots&lt; t_m=t</em>{j+1}$, $I(s<em>i) = \int</em>{0}^{s<em>i}\Delta(u)dW(u)$, $I(s</em>{i+1}) = \int<em>{0}^{s</em>{i+1}}\Delta(u)dW(u)$</p><script type="math/tex; mode=display">\begin{eqnarray}\sum_{i=0}^{m-1}[I(s_{i+1})-I(s_i)]^2 &=& \sum_{i=0}^{m-1}\left[\int_{s_i}^{s_{i+1}}\Delta(u)dW(u)\right]^2 \\ &=& \Delta^2(t_j)\sum_{i=0}^{m-1}\left[W(s_{i+1})-W(s_i)\right]^2\end{eqnarray}</script><p>Let $\max\limits<em>{0 \leq k \leq m-1}(s</em>{k+1}-s_k) \to 0$ and $m \to \infty$, according to the quadratic variation of Brownian Motion, we get</p><script type="math/tex; mode=display">\begin{eqnarray}\lim_{m \to \infty}\Delta^2(t_j)\sum_{i=0}^{m-1}\left[W(s_{i+1})-W(s_i)\right]^2 &=& \Delta^2(t_j)\lim_{m \to \infty}\sum_{i=0}^{m-1}\left[W(s_{i+1})-W(s_i)\right]^2 \\&=& \Delta^2(t_j)(t_{j+1}-t_j) \\&=& \int_{t_{j}}^{t_{j+1}}\Delta^2(u)du\end{eqnarray}</script><p>therefore, </p><script type="math/tex; mode=display">\begin{eqnarray}[I,I](t) &=& \sum_{j=0}^{k-1}\Delta^2(t_j)(t_{j+1}-t_j) + \Delta^2(t_k)(t-t_k) \\&=& \sum_{j=0}^{k-1}\int_{t_{j}}^{t_{j+1}}\Delta^2(u)du + \int_{t_{k}}^{t}\Delta^2(u)du \\&=& \int_{0}^{t}\Delta^2(u)du\end{eqnarray}</script><p>and</p><script type="math/tex; mode=display">dI(t)dI(t) = \Delta^2(t)dt</script><p><strong>Quadratic Variation of Ito Integral is a random variable, path by path. It’s average level is the variance of Integral integral (Ito Isometry).</strong></p></li></ul><h3 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h3><script type="math/tex; mode=display">I(t) = \int_{0}^{t}\Delta(u)dW(u) \tag{1}</script><p>In equation (1), there is an assumption that $I(0) = 0$.</p><script type="math/tex; mode=display">I(t) = I(0) + \int_{0}^{t}\Delta(u)dW(u) \tag{2}</script><p>In equation (2), we don’t know the value of $I(0)$.</p><script type="math/tex; mode=display">dI(t) = \Delta(t)dW(t) \tag{3}</script><p>The differential form of equation (1) and equation (2) are equation (3).</p><h2 id="Ito-Integral-for-general-function"><a href="#Ito-Integral-for-general-function" class="headerlink" title="Ito Integral for general function"></a>Ito Integral for general function</h2><p>In general, $\Delta(t)$ is no longer a simple function. However, it is possible to choose a sequence $\Delta_n(t)$ of simple processes, such that as $n \to \infty$ these processes converge to $\Delta(t)$ in mean square sense. $\Delta(t)$ is continuously varying. $\Delta_n(t)$ can be regarded as an approximation of $\Delta(t)$.</p><ul><li><p><strong>Convergence in Mean Square</strong></p><p>During the convergence, mean squared error is random because both $\Delta_n(t)$ and $\Delta(t)$ are random. We want to make convergence possible and minimize the ‘mean squared error’ by defining that</p><script type="math/tex; mode=display">\lim_{n\to \infty}\mathbb{E}\left[\int_{0}^{T}|\Delta_n(t)-\Delta(t)|^2dt\right] = 0</script><p>Here, $\Delta_n(t) \neq \Delta(t)$, but the expectation of the mean squared error is going to 0 when the frequency is going to infinity. In this sense, we call it as convergence in mean square sense (in the stochastic background).</p></li></ul><p>Therefore, ${\Delta<em>n(t)} \to \Delta(t)$ as $n \to \infty$, $\int</em>{0}^{t}\Delta_n(u)dW(u)$ has been defined on $0 \leq t \leq T$:</p><script type="math/tex; mode=display">\int_{0}^{t}\Delta(u)dW(u) = \lim_{n \to \infty}\int_{0}^{t}\Delta_n(u)dW(u)</script><h3 id="Martingale-1"><a href="#Martingale-1" class="headerlink" title="Martingale"></a>Martingale</h3><p>$I(t)$ is martingale.</p><h3 id="Moment-1"><a href="#Moment-1" class="headerlink" title="Moment"></a>Moment</h3><ul><li><p>Expectation</p><script type="math/tex; mode=display">\mathbb{E}[I(t)] = \mathbb{E}[I(t)|\mathscr{F_0}] = I(0) = 0</script></li><li><p>Ito Isometry</p><script type="math/tex; mode=display">\mathbb{E}[I^2(t)] = \mathbb{E}\left[\int_{0}^{t}\Delta^2(u)du\right]</script></li><li><p>Distribution</p><p>If $\Delta(u)$ is a deterministic function, then </p><script type="math/tex; mode=display">I(t) = \int_{0}^{t}\Delta(u)dW(u) \sim N\left(0,\mathbb{E}\left[\int_{0}^{t}\Delta^2(u)du\right]\right)</script></li></ul><h3 id="Quadratic-Variation-1"><a href="#Quadratic-Variation-1" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h3><p>$<a href="t">I,I</a> = \int_{0}^{t}\Delta^2(u)du$ </p><p>$dI(t)dI(t) = \Delta^2(t)dt$</p><h3 id="Continuity"><a href="#Continuity" class="headerlink" title="Continuity"></a>Continuity</h3><p>$I(t)$ is continuous.</p><h3 id="Adaptivity"><a href="#Adaptivity" class="headerlink" title="Adaptivity"></a>Adaptivity</h3><p>$I(t)$ is $\mathscr{F_t}$-measurable</p><h3 id="Linearity"><a href="#Linearity" class="headerlink" title="Linearity"></a>Linearity</h3><ul><li><p>$\int<em>{0}^{t}\Delta(u) \pm \Gamma(u)dW(u) = \int</em>{0}^{t}\Delta(u)dW(u) \pm \int_{0}^{t}\Gamma(u)dW(u) $</p></li><li><p>$\int<em>{0}^{t}c\Delta(u) dW(u) = c\int</em>{0}^{t}\Delta(u)dW(u)$, for every constant $c$</p></li></ul><h1 id="Stratonovich-Integral"><a href="#Stratonovich-Integral" class="headerlink" title="Stratonovich Integral"></a>Stratonovich Integral</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Ito-Integral&quot;&gt;&lt;a href=&quot;#Ito-Integral&quot; class=&quot;headerlink&quot; title=&quot;Ito Integral&quot;&gt;&lt;/a&gt;Ito Integral&lt;/h1&gt;&lt;h2 id=&quot;Why-do-we-need-Ito-Integr
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/tags/Stochastic-Calculus/"/>
    
  </entry>
  
  <entry>
    <title>Brownian Motion</title>
    <link href="http://yoursite.com/2020/08/11/Stochastic%20Calculus%20-%20Brownian%20Motion/"/>
    <id>http://yoursite.com/2020/08/11/Stochastic Calculus - Brownian Motion/</id>
    <published>2020-08-11T04:00:00.000Z</published>
    <updated>2020-08-13T09:11:44.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Definition-of-Brownian-Motion"><a href="#Definition-of-Brownian-Motion" class="headerlink" title="Definition of Brownian Motion"></a>Definition of Brownian Motion</h1><h2 id="Symmetric-Random-Walk"><a href="#Symmetric-Random-Walk" class="headerlink" title="Symmetric Random Walk"></a>Symmetric Random Walk</h2><p>Consider that we toss a fair coin independently for each time. The initial position  $M_0 = 0$. A random variable $X_j$ is defined as</p><script type="math/tex; mode=display">X_j = \begin{cases}1 ~~~\text{if H, where $P(H) = \frac{1}{2}$} \\-1 ~~~\text{if T, where $P(T) = \frac{1}{2}$}\end{cases}</script><p>Then the position after $k$ tosses can be expressed as:</p><script type="math/tex; mode=display">M_k = M_0 + \sum_{i=1}^{k}X_j, k = 1, 2, 3 \cdots</script><p>Here, $X_j$ are independent. $\mathbb{E}[X_j] = 0, \mathbb{Var}[X_j] = 1$.</p><h3 id="Independent-Increments"><a href="#Independent-Increments" class="headerlink" title="Independent Increments"></a>Independent Increments</h3><ul><li><p>For $0 = k<em>0&lt;k_1&lt;\cdots&lt;k_m$, $M</em>{k<em>1} - M</em>{k<em>0}, M</em>{k<em>2} - M</em>{k<em>1}, \cdots, M</em>{k<em>m} - M</em>{k_{m-1}}$ are independent.</p></li><li><p>For any two time point $i$ and $i+1$ (toss time $k<em>{i+1}$ and $k</em>{i}$), $M<em>{k_i+1} - M</em>{k<em>{i}} = \sum\limits</em>{j=k<em>i+1}^{k</em>{i+1}}X_j$</p></li></ul><h3 id="Moments"><a href="#Moments" class="headerlink" title="Moments"></a>Moments</h3><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[M_{k_{i+1}}-M_{k_{i}}] &=& 0 \\\mathbb{Var}[M_{k_{i+1}}-M_{k_{i}}] &=& \mathbb{Var}\left[\sum\limits_{j=k_i+1}^{k_{i+1}}X_j\right] = \left[\sum\limits_{j=k_i+1}^{k_{i+1}}\mathbb{Var}[X_j]\right] = k_{i+1}-k_i\end{eqnarray}</script><h3 id="Martingale-Property"><a href="#Martingale-Property" class="headerlink" title="Martingale Property"></a>Martingale Property</h3><p>$ \forall k &lt; l$, </p><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[M_l|\mathscr{F_k}] &=& \mathbb{E}[M_l - M_k+M_k|\mathscr{F_k}] \\&=& \mathbb{E}[M_l-M_k|\mathscr{F_k}] + \mathbb{E}[M_k|\mathscr{F_k}] \\&=& \mathbb{E}[M_l-M_k] + M_k \\&=& M_k\end{eqnarray}</script><p>here, $\mathscr{F_k}$ contains all the information at time $k$. Therefore, $\mathbb{E}[M_k|\mathscr{F_k}]$ is a constant $M_k$, $\mathbb{E}[M_l-M_k|\mathscr{F_k}]$ only depends on the time interval $(k,l)$, which is dependent to $(0,k]$. </p><h3 id="Quadratic-Variation"><a href="#Quadratic-Variation" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h3><script type="math/tex; mode=display">[M,M]_k = \sum\limits_{j=1}^{k}(M_j-M_{j-1})^2 =\sum\limits_{j=1}^{k}(X_j)^2 = \sum\limits_{j=1}^{k}1 = k</script><ul><li>Quadratic variation is calculated by one path.</li><li>Variance of the increments is calculated by every path.</li></ul><script type="math/tex; mode=display">\mathbb{Var}[M_{j}-M_{0}] =\mathbb{Var}\left[\sum\limits_{j=1}^{k}X_j\right] = \left[\sum\limits_{j=1}^{k}\mathbb{Var}[X_j]\right] = k</script><h2 id="Scaled-Random-Walk"><a href="#Scaled-Random-Walk" class="headerlink" title="Scaled Random Walk"></a>Scaled Random Walk</h2><p>Now, we consider to revise the symmetric random walk. If we toss more than one times during a time interval (<strong>speed up time</strong>), let’s say $n$ times; and after each toss, the movement is $\frac{1}{\sqrt{n}}$ or $-\frac{1}{\sqrt{n}}$ instead of $1$ or $-1$ (<strong>scale down the step</strong>). W^n(t) \to \text{Normal}, n \to \inftyThen the position is</p><script type="math/tex; mode=display">W^{n}(t) = \frac{1}{\sqrt{n}}M_{nt}</script><p>For example,</p><script type="math/tex; mode=display">W^{100}(t) = \frac{1}{10}M_{100t}, ~~ 100t = 1,2,3,\cdots</script><p>$t = 0.01, 0.02, 0.03, \cdots$ and </p><script type="math/tex; mode=display">W^{100}(0.51) = \frac{1}{10}M_{51} = \frac{1}{10}\left(M_0+\sum_{j=1}^{51}X_j\right)</script><h3 id="Moment"><a href="#Moment" class="headerlink" title="Moment"></a>Moment</h3><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[W^{n}(t)-W^{n}(s)] &=& \mathbb{E}\left[\frac{1}{\sqrt{n}}M_{nt} - \frac{1}{\sqrt{n}}M_{ns}\right] \\&=& \mathbb{E}\left[\frac{1}{\sqrt{n}}\sum_{j=ns+1}^{nt}X_j\right] \\&=& \frac{1}{\sqrt{n}}\sum_{j=ns+1}^{nt}\mathbb{E}\left[X_j\right] = 0 \\\mathbb{Var}[W^{n}(t)-W^{n}(s)] &=& \mathbb{Var}\left[\frac{1}{\sqrt{n}}M_{nt} - \frac{1}{\sqrt{n}}M_{ns}\right] \\&=& \frac{1}{n}\mathbb{Var}[M_{nt}-M_{ns}] \\&=& \frac{nt-ns}{n} = t-s\end{eqnarray}</script><h3 id="Independent-Increments-1"><a href="#Independent-Increments-1" class="headerlink" title="Independent Increments"></a>Independent Increments</h3><h3 id="Martingale-Property-1"><a href="#Martingale-Property-1" class="headerlink" title="Martingale Property"></a>Martingale Property</h3><p>$\forall s &lt; t$</p><script type="math/tex; mode=display">\mathbb{E}[W^{n}(t)|\mathscr{F}_s] = W^{n}(s)</script><p>$\mathscr{F_s}$ is the $\sigma$-algebra of information available at time $s$, which is the knowledge of the first $ns$ coin tosses. Here, $W^{n}(s)$ depends only on the first $ns$ coin tosses, so $W^{n}(s)$ is $\mathscr{F_s}$-measurable.</p><h3 id="Quadratic-Variation-1"><a href="#Quadratic-Variation-1" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h3><script type="math/tex; mode=display">\begin{eqnarray}[W^{n},W^{n}](t) &=& \sum_{i=1}^{nt}\left(W^{n}\left(\frac{i}{n}\right)-W^{n}\left(\frac{i-1}{n}\right)\right)^2 \\&=& \sum_{i=1}^{nt}\left[\frac{1}{\sqrt{n}}(M_i-M_{i-1}) \right]^2 \\&=& \sum_{i=1}^{nt}\left[\frac{1}{\sqrt{n}}X_i \right]^2 = nt \times\frac{1}{n} = t\end{eqnarray}</script><h2 id="Brownian-Motion"><a href="#Brownian-Motion" class="headerlink" title="Brownian Motion"></a>Brownian Motion</h2><p>Now, when the $n \to \infty$, the scaled random walk is going to be Brownian Motion. That is to say,</p><script type="math/tex; mode=display">W^n(t) \to \text{Normal}, n \to \infty</script><h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><ul><li><p>Calculate the Moment Generating Function (MGF) of $W^n(t)$</p><script type="math/tex; mode=display">\begin{eqnarray}\phi_n(u) &=& \mathbb{E}\left[e^{uW^n(t)}\right] = \mathbb{E}\left[e^{u\frac{1}{\sqrt{n}}M_{nt}}\right] \\&=& \mathbb{E}\left[e^{\frac{u}{\sqrt{n}}(X_1+X_2+\cdots+X_{nt})}\right] \\&=& \mathbb{E}\left[e^{\frac{u}{\sqrt{n}}X_1}e^{\frac{u}{\sqrt{n}}X_2}\cdots e^{\frac{u}{\sqrt{n}}X_{nt}}\right]  \end{eqnarray}</script><p>Here, because $X_j$ are independent, the expectation can be split into each term</p><script type="math/tex; mode=display">\begin{eqnarray}&=& \mathbb{E}\left[e^{\frac{u}{\sqrt{n}}X_1}\right] \mathbb{E}\left[e^{\frac{u}{\sqrt{n}}X_2}\right] \cdots \mathbb{E}\left[e^{\frac{u}{\sqrt{n}}X_{nt}}\right] \\&=& \left[\frac{1}{2}\left( e^{\frac{u}{\sqrt{n}}} + e^{-\frac{u}{\sqrt{n}}}\right)\right]^{nt}\end{eqnarray}</script></li><li><p>Take the limit of MGF of $W^{n}(t)$</p><script type="math/tex; mode=display">\phi_n(u) =\left[\frac{1}{2}\left( e^{\frac{u}{\sqrt{n}}} + e^{-\frac{u}{\sqrt{n}}}\right)\right]^{nt}</script><script type="math/tex; mode=display">\ln\phi_n(u) =nt \ln\left[\frac{1}{2}\left( e^{\frac{u}{\sqrt{n}}} + e^{-\frac{u}{\sqrt{n}}}\right)\right]</script><p>Let $\lambda = \frac{1}{\sqrt{n}}$, then</p><script type="math/tex; mode=display">\ln\phi_n(u) =\frac{t}{\lambda^2}\ln\left[\frac{1}{2}\left( e^{u\lambda} + e^{-u\lambda}\right)\right]</script><p>According to the Taylor Expansion:</p><script type="math/tex; mode=display">e^{u\lambda} = 1 + u\lambda + \frac{1}{2}(u\lambda)^2+o(u^2\lambda^2) \\e^{-u\lambda} = 1 - u\lambda + \frac{1}{2}(-u\lambda)^2+o(u^2\lambda^2) \\\ln\left[1 + \frac{1}{2}u^2\lambda^2\right] = \frac{1}{2}u^2\lambda^2 + o(u^2\lambda^2)</script><p>We get</p><script type="math/tex; mode=display">\begin{eqnarray}\ln\phi_n(u) &=&\frac{t}{\lambda^2}\ln\left[1+\frac{1}{2}u^2\lambda^2+o(u^2\lambda^2)\right] \\&=& \frac{t}{\lambda^2} \left[\frac{1}{2}u^2\lambda^2+o(u^2\lambda^2)\right] \\&=& \frac{1}{2}u^2t + \frac{t}{\lambda^2}o(u^2\lambda^2) \\&=& \frac{1}{2}u^2t + o(\lambda^4)\end{eqnarray}</script><p>When $n \to \infty$, $\lambda \to 0$, </p><script type="math/tex; mode=display">\lim_{\lambda \to 0}\ln\phi_n(u) = \frac{1}{2}u^2t</script><p>Therefore,</p><script type="math/tex; mode=display">\lim_{\lambda \to 0}\phi_n(u) = e^{\frac{1}{2}u^2t}</script></li><li><p>Consider a random variable $Y$ follows a Normal Distribution $N(0,t)$, the pdf is</p><script type="math/tex; mode=display">f_Y(x) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}</script><p>the MGF of $Y \sim N(0,t)$ is</p><script type="math/tex; mode=display">\begin{eqnarray}\phi_Y(u) &=& \mathbb{E}[e^{uY}] = \int_{-\infty}^{\infty}e^{ux}\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}dx \\&=&\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi t}}e^{-\frac{(x-ut)^2}{2t}}e^{\frac{1}{2}u^2t}dx \\&=& e^{\frac{1}{2}u^2t} \int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi t}}e^{-\frac{(x-ut)^2}{2t}}dx \\&=& e^{\frac{1}{2}u^2t}\end{eqnarray}</script></li><li><p>The two MGFs are the same, so</p><script type="math/tex; mode=display">W^n(t) \to \text{Normal}, n \to \infty</script></li></ul><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Consider a probability space $(\Omega, \mathscr{F}, \mathbb{P})$ and suppose there is a continuous function $w(t), t \geq 0$ that satisfies $w(0) = 0$ and depends on $w$. Then $w(t)$ is a <strong>Brownian Motion</strong> if for all $0=t<em>0&lt;t_1&lt;t_2&lt;\cdots&lt;t_m$, the increments $w(t_1)-w(t_0), w(t_2)-w(t_1),\cdots,w(t_m)-w(t</em>{m-1})$ are independent and each increment is normal distribution with $\mathbb{E}[w(t<em>{i+1})-w(t</em>{i})] = 0$ and $\mathbb{Var}[w(t<em>{i+1})-w(t</em>{i})]=t_{i+1}-t_i$.</p><ul><li>$w(t)-w(s) \sim N(0,t-s)$. The standard deviation is $\sqrt{t-s}$.</li><li>$w(t) = w(t)-w(0) \sim N(0,t)$. The standard deviation is $\sqrt{t}$.</li></ul><h3 id="Filtration-amp-Adaptivity"><a href="#Filtration-amp-Adaptivity" class="headerlink" title="Filtration &amp; Adaptivity"></a>Filtration &amp; Adaptivity</h3><p>A filtration is a collection of $\sigma$-algebras $\mathscr{F_t}, t \geq 0$ satisfying that information accumulates, $\mathscr{F_s} \subset \mathscr{F_t}, ~~\forall s &lt; t$</p><p>If we can use the information in $(0,s)$ to determine the $w_s$, then we call it as $\mathscr{F_s}$-measurable, which is also called adapt processes. Adaptivity is always related to a filtration.</p><ul><li>Let $\Delta(t), t \geq 0$ be a stochastic process. $\Delta(t)$ is <strong>adapted</strong> to a filtration $\mathscr{F_t}$ if for $\forall t \geq 0$, $\Delta(t)$ is $\mathscr{F_t}$-measurable.</li></ul><h3 id="Independent-Increments-2"><a href="#Independent-Increments-2" class="headerlink" title="Independent Increments"></a>Independent Increments</h3><p>$\forall 0 \leq t &lt; u, w(u)-w(t)$ is independent of $\mathscr{F_t}$</p><h3 id="Martingale-Property-2"><a href="#Martingale-Property-2" class="headerlink" title="Martingale Property"></a>Martingale Property</h3><p>$0 \leq s \leq t, \mathbb{E}[w(t)|\mathscr{F_s}] = w(s)$</p><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{E}[w(t)|\mathscr{F_s}] &=& \mathbb{E}[w(t)-w(s) + w(s) |\mathscr{F_s}] \\&=& \mathbb{E}[w(t)-w(s)|\mathscr{F_s}] + \mathbb{E}[w(s) |\mathscr{F_s}] \\&=& \mathbb{E}[w(t)-w(s)] + w(s) \\&=& w(s)\end{eqnarray}</script><h3 id="Quadratic-Variation-2"><a href="#Quadratic-Variation-2" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h3><ul><li><p>First-Order Variation means the up and down oscillation:</p><p>for $t \in (0,T)$, consider two time point $t_1$ and $s_2$ satisfying $0 &lt; t_1&lt;t_2&lt;T$</p></li></ul><script type="math/tex; mode=display">\begin{eqnarray}FV_T(f) &=& [f(t_1)-f(0)] - [f(t_2)-f(t_1)] + [f(T)-f(t_2))] \\&=& \int_{0}^{t_1}f'(t)dt + \int_{t_1}^{t_2}-f'(t)dt + \int_{t_2}^{T}f'(t)dt \\&=& \int_{0}^{T}|f'(t)|dt\end{eqnarray}</script><p>​        in general, choose a partition $\pi = {t_0, t_1,\cdots, t_n}$ where $0=t_0 &lt; t_1&lt;t_2&lt;\cdots&lt;t_n = T$. Define</p><script type="math/tex; mode=display">FV_T(f) = \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}|f(t_{j+1})-f(t_j)|, ~~~||\pi|| = \max_{1\leq j \leq n}(t_j - t_{j-1})</script><p>​        As $n \to \infty$, $||\pi|| \to 0$. According to the Mean Value Theorem, $\exists ~ t_j^*$ satisfying</p><script type="math/tex; mode=display">FV_T(f) = \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}|f'(t_{j}^{*})(t_{j+1}-t_j)| = \lim_{||\pi|| \to 0}(t_{j+1}-t_j)\sum_{j=0}^{n-1}|f'(t_{j}^{*})| = \int_{0}^{T}|f'(t)|dt</script><ul><li><p>Quadratic Variation</p><script type="math/tex; mode=display">[f,f](T) = \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}(f(t_{j+1})-f(t_j))^2, ~~~||\pi|| = \max_{1\leq j \leq n}(t_j - t_{j-1})</script><ul><li><p>Conclusion 1: suppose $f$ has a continuous derivative, then </p><script type="math/tex; mode=display">[f,f](T)=0</script><p><strong>Proof</strong>:</p><script type="math/tex; mode=display">\begin{eqnarray}\sum_{j=0}^{n-1}(f(t_{j+1})-f(t_j))^2 &=& \sum_{j=0}^{n-1}|f'(t_{j}^{*})|^2(t_{j+1}-t_j)(t_{j+1}-t_j) \\&\leq& ||\pi||\sum_{j=0}^{n-1}|f'(t_{j}^{*})|^2(t_{j+1}-t_j)\end{eqnarray}</script><script type="math/tex; mode=display">\begin{eqnarray}[f,f](T) &\leq& \lim_{||\pi|| \to 0}||\pi|| \times \lim_{||\pi|| \to 0}\sum_{j=0}^{n-1}|f'(t_{j}^{*})|^2(t_{j+1}-t_j) \\&=& 0 \times \int_{0}^{T}|f'(t)|dt\end{eqnarray}</script><p>because $f’(t)$ is continuous, then $\exists M&gt;0 \in[0,T]$ s.t. $|f’(t)| \leq M &lt; \infty$</p><script type="math/tex; mode=display">[f,f](T) \leq 0</script><p>and by definition the quadratic variation should be greater than 0, we get</p><script type="math/tex; mode=display">[f,f](T) = 0</script></li><li><p>Conclusion 2 (quadratic variation of Brownian Motion): Let $w(t)$ be Brownian motion, then  </p><script type="math/tex; mode=display">\left[w,w\right](T) = T</script><p>$\forall  T \geq 0$ almost surely.</p><p><strong>Proof</strong>:<br>Let $\pi = {t_0, t_1,\cdots, t_n}$ where $0=t_0 &lt; t_1&lt;t_2&lt;\cdots&lt;t_n = T$ be a partition of $[0,T]$, and then define </p><script type="math/tex; mode=display">Q_{\pi} = \sum_{j=0}^{n-1}(w(t_{j+1})-w(t_j))^2</script><ul><li><p>Expectation</p><script type="math/tex; mode=display">\begin{eqnarray}    \mathbb{E}[Q_{\pi}] &=& \sum\limits_{j=0}^{n-1}\mathbb{E}(w(t_{j+1})-w(t_j))^2 = \sum\limits_{j=0}^{n-1}\mathbb{Var}[w(t_{j+1})-w(t_j)] + (\mathbb{E}[w(t_{j+1})-w(t_j)])^2 \\    &=& \sum\limits_{j=0}^{n-1}\mathbb{Var}[w(t_{j+1})-w(t_j)] + 0^2 \\    &=& \sum\limits_{j=0}^{n-1}(t_{j+1}-t_{j}) = t_{n}-t_0 = T    \end{eqnarray}</script></li><li><p>Variance: </p><p>because $w(t<em>{j+1})$ and $w(t</em>{j})$ are independent, and $w(t<em>{j+1})-w(t_j) \sim N(0,t</em>{j+1}-t_j)$ then</p><script type="math/tex; mode=display">\begin{eqnarray}  \mathbb{Var}[Q_{\pi}] &=& \mathbb{Var}\left[\sum\limits_{j=0}^{n-1}(w(t_{j+1})-w(t_j))^2\right] \\  &=& \sum\limits_{j=0}^{n-1}\mathbb{Var}[(w(t_{j+1})-w(t_j))^2] \\  &=& \sum\limits_{j=0}^{n-1}\mathbb{E}[(w(t_{j+1})-w(t_j))^4] - \mathbb{E}^2[(w(t_{j+1})-w(t_j))^2] \\  &=& \sum\limits_{j=0}^{n-1}\mathbb{E}[(w(t_{j+1})-w(t_j))^4] - \mathbb{Var}^2[w(t_{j+1})-w(t_j)]  \end{eqnarray}</script><p>Let’s $Y<em>j = w(t</em>{j+1})-w(t<em>j) \sim N(0,t</em>{j+1}-t<em>j)$, $Q</em>{\pi} = Y_j^2$, then</p><script type="math/tex; mode=display">  \begin{eqnarray}  \mathbb{Var}[Y_j^2] &=& \sum\limits_{j=0}^{n-1}\mathbb{E}[Y_j^4] - \mathbb{Var}^2[Y_j] \\  &=& \sum\limits_{j=0}^{n-1}\mathbb{E}[Y_j^4] - (t_{j+1}-t_j)^2\end{eqnarray}</script><p>and</p><script type="math/tex; mode=display">\mathbb{E}[Y_j^4] = 3\mathbb{Var}^2[Y_j] = 3(t_{j+1}-t_j)^2</script><blockquote><p>Proof:</p><p>Because</p><script type="math/tex; mode=display">X \sim N(0,1), \mathbb{E}[X^4] = 3 \\</script><p>consider $X \sim N(0,\sigma^2), $ because</p><script type="math/tex; mode=display">Y = \frac{x-0}{\sigma} \sim N(0,1) \\\mathbb{E}\left[\frac{x^4}{\sigma^4}\right] = 3 \\\mathbb{E}[X^4] = 3\sigma^4 \\</script></blockquote><p>Therefore,</p><script type="math/tex; mode=display">\begin{eqnarray}  \mathbb{Var}[Y_j^2] &=& 2\sum\limits_{j=0}^{n-1}(t_{j+1}-t_j)^2 \\  &\leq& 2||\pi||\sum\limits_{j=0}^{n-1}(t_{j+1}-t_j) = 2||\pi||T\end{eqnarray}</script><p>According to the Squeeze Theorem</p><script type="math/tex; mode=display">  \lim_{\pi \to 0} \mathbb{Var}[Q_{\pi}] = 0</script></li><li><p>Now, we have the expectation $\mathbb{E}[Q<em>{\pi}] = T$ and variance $\mathbb{Var}[Q</em>{\pi}] = 0$ of the quadratic variance of Brownian Motion, therefore</p></li></ul></li></ul><script type="math/tex; mode=display">[W,W](T) = Q_{\pi} = T</script></li></ul><h1 id="Some-useful-conclusions"><a href="#Some-useful-conclusions" class="headerlink" title="Some useful conclusions"></a>Some useful conclusions</h1><h2 id="dw-t-dw-t-dt"><a href="#dw-t-dw-t-dt" class="headerlink" title="$dw(t)dw(t) = dt$"></a>$dw(t)dw(t) = dt$</h2><ul><li><p>$\mathbb{E}[(w(t<em>{j+1})-w(t</em>{j}))^2] = \mathbb{Var}[w(t<em>{j+1})-w(t</em>{j})] = t<em>{j+1}-t</em>{j}$</p></li><li><p>$\mathbb{Var}[(w(t<em>{j+1})-w(t</em>{j}))^2] = 2(t<em>{j+1}-t</em>{j})^2$</p></li><li><p>$\lim\limits<em>{\pi \to 0} \sum\limits</em>{j=0}^{n-1}(w(t_{j+1})-w(t_j))^2 = T$</p></li></ul><p>Now consider</p><script type="math/tex; mode=display">\begin{eqnarray}\lim\limits_{\pi \to 0} \sum\limits_{j=0}^{n-1}(w(t_{j+1})-w(t_j))^2 = \lim\limits_{\pi \to 0} \sum\limits_{j=0}^{n-1}(w(t_{j+1})-w(t_j))(w(t_{j+1})-w(t_j)) = T \\\end{eqnarray}</script><p>which can be regarded as Riemann–Stieltjes integral</p><script type="math/tex; mode=display">\int_{0}^{T}dw(t)dw(t) = \int_{0}^{T}dt</script><p>Here, $dw(t)$ has no definition rigorously, but it is helpful for calculation.</p><h2 id="dw-t-epsilon-sqrt-dt"><a href="#dw-t-epsilon-sqrt-dt" class="headerlink" title="$dw(t) = \epsilon \sqrt{dt}$"></a>$dw(t) = \epsilon \sqrt{dt}$</h2><p>$dw(t) = \epsilon \sqrt{dt}$ is not a formal expression. The formal expression should be $w(t+\Delta t) - w(t) = \epsilon \sqrt{\Delta t}$</p><ul><li>In a small time interval $\Delta t$<script type="math/tex; mode=display">w(t+\Delta t) - w(t) = \epsilon \sqrt{\Delta t}</script></li></ul><script type="math/tex; mode=display">w(T) = w(T)-w(0) = \epsilon\sqrt{T}</script><ul><li>$dw(t)$ has no definition rigorously.</li></ul><h2 id="dw-t-dt-0"><a href="#dw-t-dt-0" class="headerlink" title="$dw(t)dt = 0$"></a>$dw(t)dt = 0$</h2><script type="math/tex; mode=display">\begin{eqnarray}\left| \sum_{j=0}^{n-1}(t_{j+1}-t_j)(w(t_{j+1})-w(t_{t_j})) \right| &\leq& \sum_{j=0}^{n-1}|t_{j+1}-t_j||w(t_{j+1})-w(t_{t_j})| \\&\leq& \max_{0 \leq j\leq n-1}|w(t_{j+1})-w(t_{t_j})|\sum_{j=0}^{n-1}t_{j+1}-t_j\end{eqnarray}</script><p>as $||\pi|| \to 0$, $\max<em>{0 \leq j\leq n-1}|w(t</em>{j+1})-w(t_{t_j})| \to 0$</p><script type="math/tex; mode=display">\lim_{||\pi|| \to 0} \sum_{j=0}^{n-1}(t_{j+1}-t_j)(w(t_{j+1})-w(t_{t_j})) = 0 \\\int_{0}^{T}dtdw(t) = 0 \\</script><h2 id="dtdt-0"><a href="#dtdt-0" class="headerlink" title="$dtdt = 0$"></a>$dtdt = 0$</h2><h1 id="Levy’s-Theorem"><a href="#Levy’s-Theorem" class="headerlink" title="Levy’s Theorem"></a>Levy’s Theorem</h1><p>Let $M(t), t \geq 0$ be a martingale, relative to $\mathcal{F}, t \geq 0$. Assume $M(0) = 0$, $M(t)$ has continuous paths and the quadratic variation of $M(t)$ equals $t$ for all $t &gt; 0$. Then $M(t)$ is a Brownian Motion.</p><p>That is to say, any process can be Brownian Motion if the above 4 conditions are satisfied</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Definition-of-Brownian-Motion&quot;&gt;&lt;a href=&quot;#Definition-of-Brownian-Motion&quot; class=&quot;headerlink&quot; title=&quot;Definition of Brownian Motion&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Calculus" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Calculus/"/>
    
    
      <category term="Finance" scheme="http://yoursite.com/tags/Finance/"/>
    
      <category term="Asset Pricing" scheme="http://yoursite.com/tags/Asset-Pricing/"/>
    
      <category term="Brownian Motion" scheme="http://yoursite.com/tags/Brownian-Motion/"/>
    
  </entry>
  
  <entry>
    <title>Poisson Process</title>
    <link href="http://yoursite.com/2020/08/09/Stochastic%20Processes%20-%20Poisson%20Process/"/>
    <id>http://yoursite.com/2020/08/09/Stochastic Processes - Poisson Process/</id>
    <published>2020-08-09T04:00:00.000Z</published>
    <updated>2020-08-13T16:36:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Exponential-Distribution"><a href="#Exponential-Distribution" class="headerlink" title="Exponential Distribution"></a>Exponential Distribution</h1><p>If $\tau \sim \exp(\lambda)$, then the pdf is</p><script type="math/tex; mode=display">f_{\tau}(t) = \begin{cases}\lambda e^{-\lambda t},& t \geq 0 \\0,& t < 0\end{cases}</script><p>the cdf is</p><script type="math/tex; mode=display">F_{\tau}(t) = \begin{cases}1-e^{-\lambda t},& t \geq 0 \\0,& t < 0\end{cases}</script><p>The expectation is</p><script type="math/tex; mode=display">\mathbb{E}[\tau] = \int_{0}^{\infty}tf_{\tau}(t)dt = \frac{1}{\lambda}</script><p>The variance is</p><script type="math/tex; mode=display">\mathbb{E}[\tau^2] = \int_{0}^{\infty}t^2f_{\tau}(t)dt = \frac{2}{\lambda^2} \\\mathbb{Var}[\tau] = \mathbb{E}[\tau^2] - \mathbb{E}^2[\tau]</script><p>Memoryless</p><script type="math/tex; mode=display">\mathbb{P}(\tau > u) = 1 -\mathbb{P}(\tau \leq u) = 1-(1-e^{-\lambda u})=e^{-\lambda u}</script><script type="math/tex; mode=display">\mathbb{P}(\tau > u+v | \tau >v) = \frac{\mathbb{P}(\tau > u+v , \tau >v)}{\mathbb{P}(\tau >v)} = \frac{\mathbb{P}(\tau > u+v) }{\mathbb{P}(\tau >v)} = e^{-\lambda u}</script><h1 id="Poisson-Process"><a href="#Poisson-Process" class="headerlink" title="Poisson Process"></a>Poisson Process</h1><p>$\tau_1, \tau_1,  \cdots, \tau_n, \cdots$ are $i.i.d.$ $\exp(\lambda)$. $\mathbb{\tau_i} = \frac{1}{\lambda}, i = 1, 2, \cdots$</p><p>The first jump occurs at time $\tau<em>1$, the second jump occurs at time $\tau_1+\tau_2$, the n-th jump occurs at time $\sum\limits</em>{k=1}^{n}\tau<em>k$. The ${\tau_k}</em>{k=1}^{\infty}$ is called inter arrival times. $S<em>k = \sum\limits</em>{i=1}^{k}\tau<em>i$ are arrival times. Define $N(t)$ is the number of jumps that occur <em>_at or before</em></em> time $t$, which mean that $N(t)$ is right-continuous. $N(t)$ is called Poisson Process.</p><h2 id="Arrival-Times"><a href="#Arrival-Times" class="headerlink" title="Arrival Times"></a>Arrival Times</h2><p>$S<em>n = \sum\limits</em>{i=1}^{n}\tau_i$ are arrival times. $S_n$ is a Gamma Distribution. </p><script type="math/tex; mode=display">g_{S_n} = \frac{(\lambda s)^{n-1}}{(n-1)!}\lambda e^{-\lambda s}, s \geq 0</script><p>The jumps are arriving at an average rate of $\lambda$ per unit time. $\lambda$ is also the intensity of Poisson Process.</p><h2 id="Poisson-Distribution"><a href="#Poisson-Distribution" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h2><p>Given $N(t)$, $\lambda$, when the time $t$ is fixed, then $N(t)$ is a Poisson Distribution with parameter $\lambda t$. </p><script type="math/tex; mode=display">\mathbb{P}(N(t)=k) = \frac{(\lambda t)^k}{k!}e^{-\lambda t}, k = 0, 1, 2, \cdots</script><p><strong>Proof</strong></p><script type="math/tex; mode=display">N(t) \geq k \Leftrightarrow S_k \leq t</script><script type="math/tex; mode=display">\begin{eqnarray}\mathbb{P}(N(t) \geq k) &=& \mathbb{P}(S_k\leq t) \\&=& \int_0^{t}\frac{(\lambda s)^{k-1}}{(k-1)!}\lambda e^{-\lambda s} \\&=& \frac{\lambda^k}{(k-1)!}\int_0^{t}s^{k-1}e^{-\lambda s}ds \\\\\\\mathbb{P}(N(t) \geq k+1) &=& \mathbb{P}(S_{k+1} \leq t) \\&=& \int_0^{t}\frac{(\lambda s)^{k}}{k!}\lambda e^{-\lambda s} \\&=& \frac{\lambda^{k}}{k!} \left(s^ke^{-\lambda s}|_{t}^{0} - \int_t^{0}e^{-\lambda s}ks^{k-1}ds \right) \\&=& \frac{(\lambda t)^{k}}{k!} e^{-\lambda t} + \frac{\lambda^k}{(k-1)!}\int_0^{t}e^{-\lambda s}s^{k-1}ds  \\\\\\\mathbb{P}(N(t) = k) &=& \mathbb{P}(N(t) \geq k+1) - \mathbb{P}(N(t) \geq k) \\&=& \frac{(\lambda t)^{k}}{k!} e^{-\lambda t}\end{eqnarray}</script><h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><h3 id="Increments"><a href="#Increments" class="headerlink" title="Increments"></a>Increments</h3><p>Let $0 = t<em>0 &lt; t_1 &lt; t_2 &lt; \cdots &lt; t_n$ be given. Then $N(t_1) - N(t_0), N(t_2) - N(t_1), \cdots, N(t_n) - N(t</em>{n-1})$ are stationary and independent, and $N(t<em>{j+1}) - N(t_j) \sim \text{Poi}((t</em>{j+1}-t_j)\lambda), j = 1,2,\cdots, n-1$</p><p>It means that, given $s &lt; t$, </p><ul><li><p>$N(t)-N(s)$ shares the same distribution with $N(t-s)$: $N(t)-N(s) \sim \sim \text{Poi}((t-s)\lambda)$</p></li><li><p>$\mathbb{E}(N(t)-N(s)) = \lambda(t-s)$</p></li><li>$\mathbb{Var}(N(t)-N(s))=\lambda(t-s)$</li></ul><h3 id="Relationship"><a href="#Relationship" class="headerlink" title="Relationship"></a>Relationship</h3><p>Poisson Distribution</p><p>Exponential Distribution</p><p>Poisson Process</p><h1 id="Compensative-Poisson-Process"><a href="#Compensative-Poisson-Process" class="headerlink" title="Compensative Poisson Process"></a>Compensative Poisson Process</h1><h1 id="Compound-Poisson-Process"><a href="#Compound-Poisson-Process" class="headerlink" title="Compound Poisson Process"></a>Compound Poisson Process</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Exponential-Distribution&quot;&gt;&lt;a href=&quot;#Exponential-Distribution&quot; class=&quot;headerlink&quot; title=&quot;Exponential Distribution&quot;&gt;&lt;/a&gt;Exponential Di
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Probability" scheme="http://yoursite.com/categories/Mathematics/Probability/"/>
    
      <category term="Stochastic Processes" scheme="http://yoursite.com/categories/Mathematics/Probability/Stochastic-Processes/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Stochastic Processes" scheme="http://yoursite.com/tags/Stochastic-Processes/"/>
    
  </entry>
  
  <entry>
    <title>JSON Basic</title>
    <link href="http://yoursite.com/2020/04/04/Big%20Data%20JSON%20Basics/"/>
    <id>http://yoursite.com/2020/04/04/Big Data JSON Basics/</id>
    <published>2020-04-04T04:00:00.000Z</published>
    <updated>2020-04-04T11:48:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Basic-JSON"><a href="#Basic-JSON" class="headerlink" title="Basic JSON"></a>Basic JSON</h1><h3 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure:"></a>Data Structure:</h3><ul><li>key / value pair</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">var studentData = &#123;</span><br><span class="line">    "student_id": 1234567,</span><br><span class="line">    "name": "John Smith",</span><br><span class="line">    "enrollment_date": "1/1/2020",</span><br><span class="line">    "location": "Tandon School, NYC",</span><br><span class="line">    "course_nums":[6024, 7865, 5512, 8194]</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Data-type"><a href="#Data-type" class="headerlink" title="Data type:"></a>Data type:</h3><p>Json Arrays</p><p>Srings</p><ul><li>0 or more Unicode characters</li><li>double quotes</li><li>backslash escapement</li></ul><p>Numbers</p><ul><li>Integer</li><li>real</li><li>no Ox, Hex</li><li>no NaN or Indfinity - use null</li></ul><h3 id="Object-in-json"><a href="#Object-in-json" class="headerlink" title="Object in json"></a>Object in json</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"student_id"</span>: <span class="number">1234567</span>,</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"John Smith"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>It can contain many key/value pairs.</p><p>which is the same as javaScript</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">student_id = <span class="number">1234567</span>,</span><br><span class="line">name = <span class="string">"John Smith"</span></span><br></pre></td></tr></table></figure><p>JavaScript</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">var sites = [</span><br><span class="line">    &#123;"student_id": 1234567, "name": "John Smith"&#125;, </span><br><span class="line">    &#123;"student_id": 1234568, "name": "Steven Bob"&#125;, </span><br><span class="line">    &#123;<span class="attr">"student_id"</span>: <span class="number">1234569</span>, <span class="attr">"name"</span>: <span class="string">"John Nash"</span>&#125;</span><br><span class="line">];</span><br><span class="line"></span><br><span class="line"># call</span><br><span class="line">sites[0].name;</span><br><span class="line"></span><br><span class="line"># revise</span><br><span class="line">sites[0].name="Alex Jack";</span><br></pre></td></tr></table></figure><p>Object Example</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">var myObj, x;</span><br><span class="line">myObj = &#123; "name":"runoob", "alexa":10000, "site":null &#125;;</span><br><span class="line"></span><br><span class="line"># call</span><br><span class="line">x = myObj.name;</span><br><span class="line"># or</span><br><span class="line">x = myObj["name"];</span><br><span class="line"></span><br><span class="line"># for loop</span><br><span class="line">for (x in myObj) &#123;</span><br><span class="line">    document.getElementById("demo").innerHTML += x + "&lt;br&gt;";</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Nested objects</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">myObj = &#123;</span><br><span class="line">    "name":"runoob",</span><br><span class="line">    "alexa":10000,</span><br><span class="line">    "sites": &#123;</span><br><span class="line">        "site1":"www.runoob.com",</span><br><span class="line">        "site2":"m.runoob.com",</span><br><span class="line">        "site3":"c.runoob.com"</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Delete object</span><br><span class="line">delete myObj.sites.site1;</span><br><span class="line"># or</span><br><span class="line">delete myObj.sites["site1"]</span><br></pre></td></tr></table></figure><p>delete just change the data to unsigned, the array length will not be changed. The array will become sparser.</p><h3 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[ <span class="string">"Google"</span>, <span class="string">"Runoob"</span>, <span class="string">"Taobao"</span> ]</span><br><span class="line"></span><br><span class="line"># for in loop</span><br><span class="line">for (i in myObj.sites) &#123;</span><br><span class="line">    x += myObj.sites[i] + "&lt;br&gt;";</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># for loop</span><br><span class="line">for (i = 0; i &lt; myObj.sites.length; i++) &#123;</span><br><span class="line">    x += myObj.sites[i] + "&lt;br&gt;";</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Parse"><a href="#Parse" class="headerlink" title="Parse"></a>Parse</h3><p><code>JSON.parse()</code> change the string data on the server to JavaScript Object.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># receive the data from server like these:</span><br><span class="line">&#123; <span class="attr">"name"</span>:<span class="string">"runoob"</span>, <span class="attr">"alexa"</span>:<span class="number">10000</span>, <span class="attr">"site"</span>:<span class="string">"www.runoob.com"</span> &#125;</span><br><span class="line"></span><br><span class="line"># convert it to JavaScript object</span><br><span class="line">var obj = JSON.parse('&#123; "name":"runoob", "alexa":10000, "site":"www.runoob.com" &#125;');</span><br></pre></td></tr></table></figure><p>parse example</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># Text Example</span><br><span class="line">var xmlhttp = new XMLHttpRequest();</span><br><span class="line">xmlhttp.onreadystatechange = function() &#123;</span><br><span class="line">    if (this.readyState == 4 &amp;&amp; this.status == 200) &#123;</span><br><span class="line">        myObj = JSON.parse(this.responseText);</span><br><span class="line">        document.getElementById("demo").innerHTML = myObj.name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">xmlhttp.open("GET", "/try/ajax/json_demo.txt", true);</span><br><span class="line">xmlhttp.send();</span><br><span class="line"></span><br><span class="line"># Array Example</span><br><span class="line">var xmlhttp = new XMLHttpRequest();</span><br><span class="line">xmlhttp.onreadystatechange = function() &#123;</span><br><span class="line">    if (this.readyState == 4 &amp;&amp; this.status == 200) &#123;</span><br><span class="line">        myArr = JSON.parse(this.responseText);</span><br><span class="line">        document.getElementById("demo").innerHTML = myArr[1];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">xmlhttp.open("GET", "/try/ajax/json_demo_array.txt", true);</span><br><span class="line">xmlhttp.send();</span><br><span class="line"></span><br><span class="line"># if there is a function in data, convert the function to string</span><br><span class="line">var text = '&#123; "name":"Runoob", "alexa":"function () &#123;return 10000;&#125;", "site":"www.runoob.com"&#125;';</span><br><span class="line">var obj = JSON.parse(text);</span><br><span class="line">obj.alexa = eval("(" + obj.alexa + ")");</span><br><span class="line"> </span><br><span class="line">document.getElementById("demo").innerHTML = obj.name + " Alexa 排名：" + obj.alexa();</span><br></pre></td></tr></table></figure><h3 id="JSON-stringify"><a href="#JSON-stringify" class="headerlink" title="JSON.stringify()"></a>JSON.stringify()</h3><p>convert JavaScript object into strings</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var obj = &#123; "name":"runoob", "alexa":10000, "site":"www.runoob.com"&#125;;</span><br><span class="line">var myJSON = JSON.stringify(obj);</span><br><span class="line">document.getElementById("demo").innerHTML = myJSON;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Basic-JSON&quot;&gt;&lt;a href=&quot;#Basic-JSON&quot; class=&quot;headerlink&quot; title=&quot;Basic JSON&quot;&gt;&lt;/a&gt;Basic JSON&lt;/h1&gt;&lt;h3 id=&quot;Data-Structure&quot;&gt;&lt;a href=&quot;#Data-St
      
    
    </summary>
    
      <category term="Computer Science" scheme="http://yoursite.com/categories/Computer-Science/"/>
    
      <category term="Big Data" scheme="http://yoursite.com/categories/Computer-Science/Big-Data/"/>
    
      <category term="JSON" scheme="http://yoursite.com/categories/Computer-Science/Big-Data/JSON/"/>
    
    
      <category term="JSON" scheme="http://yoursite.com/tags/JSON/"/>
    
      <category term="Big Data" scheme="http://yoursite.com/tags/Big-Data/"/>
    
  </entry>
  
  <entry>
    <title>Statistics Inference</title>
    <link href="http://yoursite.com/2020/04/03/Statistics%20Inference/"/>
    <id>http://yoursite.com/2020/04/03/Statistics Inference/</id>
    <published>2020-04-03T04:00:00.000Z</published>
    <updated>2020-04-03T14:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><h3 id="Neyman-Pearson-Lemma"><a href="#Neyman-Pearson-Lemma" class="headerlink" title="Neyman-Pearson Lemma"></a>Neyman-Pearson Lemma</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Inference&quot;&gt;&lt;a href=&quot;#Inference&quot; class=&quot;headerlink&quot; title=&quot;Inference&quot;&gt;&lt;/a&gt;Inference&lt;/h1&gt;&lt;h3 id=&quot;Neyman-Pearson-Lemma&quot;&gt;&lt;a href=&quot;#Neyma
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/"/>
    
      <category term="Classic Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/Classic-Statistics/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>Statistics for Linear Regression</title>
    <link href="http://yoursite.com/2020/04/03/Statistics%20Linear%20Regression/"/>
    <id>http://yoursite.com/2020/04/03/Statistics Linear Regression/</id>
    <published>2020-04-03T04:00:00.000Z</published>
    <updated>2020-04-03T14:50:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="What-is-linear-regression"><a href="#What-is-linear-regression" class="headerlink" title="What is linear regression"></a>What is linear regression</h1><p>if we have a dataset with two factors, we would like to summarize this data with a line. The goal of linear regression is to choose a slope $b$ and point $(x_0, y_0)$ that make sense. </p><script type="math/tex; mode=display">y - y_0 = b(x-x_0)</script><p>The point  we would choose is the $(\bar{x},\bar{y})$, and the slope we would choose is $r \frac{s_y}{s_x}$. </p><p>Actually We can just manipulate the point and slope by changing the slope and the point, </p><h1 id="Method-of-residuals"><a href="#Method-of-residuals" class="headerlink" title="Method of residuals"></a>Method of residuals</h1><h1 id="Estimating-errors"><a href="#Estimating-errors" class="headerlink" title="Estimating errors"></a>Estimating errors</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;What-is-linear-regression&quot;&gt;&lt;a href=&quot;#What-is-linear-regression&quot; class=&quot;headerlink&quot; title=&quot;What is linear regression&quot;&gt;&lt;/a&gt;What is lin
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/"/>
    
      <category term="Classic Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/Classic-Statistics/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/tags/Statistics/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Time Series</title>
    <link href="http://yoursite.com/2020/04/03/Time%20Series%20Introduction/"/>
    <id>http://yoursite.com/2020/04/03/Time Series Introduction/</id>
    <published>2020-04-03T04:00:00.000Z</published>
    <updated>2020-04-03T17:05:42.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Ideas-behind-time-series"><a href="#Ideas-behind-time-series" class="headerlink" title="Ideas behind time series"></a>Ideas behind time series</h2><p>One of assumptions of any model is:</p><ul><li>independence of errors / residuals</li></ul><p>This means that there should be no pattern in the residuals, and pattern means that we can find a better fit. It can be a not linear model.</p><p>Time series is one of these non-linear models. After applying the time series model, the $\sum{e_i^2}$ total error square should be reduced and the patterns on residuals are gone. Compared to the coefficient $b$ in linear regression, coefficient $a$ in time series is just a number without specific meaning.</p><h2 id="type-of-time-series-model"><a href="#type-of-time-series-model" class="headerlink" title="type of time series model"></a>type of time series model</h2><p>There are two types of time series models, one is ARMA model, and other is spectral model.</p><ul><li>ARMA model:</li></ul><script type="math/tex; mode=display">x_t = a_1x_{t-1} + a_2x_{t-1} + ... + b_1\epsilon_{t-1}+b_2\epsilon_{t_2}+...</script><ul><li>Spectral model:</li></ul><script type="math/tex; mode=display">\begin{eqnarray*}x_t &=& a_1\sin(\frac{2\pi}{5}t)+b_1\cos(\frac{2\pi}{5}t) \\&+& a_2\sin(\frac{2\pi}{7}t)+b_2\cos(\frac{2\pi}{7}t) \\&+& ...\end{eqnarray*}</script><p>There is also a difference between time series and Brownian motion. Time series is a discrete model with t from negative infinite to positive infinite. However, Brownian motion is a continuous model within finite time.</p><p>For ARMA model, there are 3 simple formats:</p><ul><li>White Noise</li></ul><script type="math/tex; mode=display">\begin{eqnarray*}x_t &=& w_t \\w_t &\sim& N(0,\sigma^2) \text{iid}\end{eqnarray*}</script><ul><li>Moving Average</li></ul><script type="math/tex; mode=display">x_t = \frac{x_{t+1}+x_{t}+x_{t-1}}{3}</script><ul><li>Auto Regression</li></ul><script type="math/tex; mode=display">x_t = 0.4 x_{t-1} + 0.4 x_{t-2} + w_t</script><h1 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h1><p>Ideally, we should simulate the time series for many times (say 100 times). Here, because they are simulated from the same equation, each realization must follow the distribution. And then We compute the expectation and covariance using the simulated data:</p><script type="math/tex; mode=display">\begin{eqnarray*}E(x_{10}) \\E(x_{20}) \\Cov(x_{10}, x_{20})\end{eqnarray*}</script><p>And theoretically, we can also compute the expectation and covariance using math, for a moving average series:</p><script type="math/tex; mode=display">\begin{eqnarray*}E(x_{10}) &=& \frac{1}{3}E(W_9+W_{10}+W_{11}) = 0 \\E(x_{20}) &=& \frac{1}{3}E(W_{19}+W_{20}+W_{21}) = 0 \\\end{eqnarray*}</script><script type="math/tex; mode=display">\begin{eqnarray*}Cov(x_{10},x_{20}) = \frac{1}{9}E(W_9W_{19} &+& W_9W_{20}+W_9W_{21} \\+W_{10}W_{19}&+&W_{10}W_{20}+W_{10}W_{21} \\+W_{11}W_{19}&+&W_{11}W_{20}+W_{11}W_{21}) \end{eqnarray*}</script><p>However, in reality, many things only have one simulation. We cannot compute the expectation and covariance based on one simulation. Then, we find some alternatives: compute the covariance with lag terms.</p><h1 id="Stationary"><a href="#Stationary" class="headerlink" title="Stationary"></a>Stationary</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;h2 id=&quot;Ideas-behind-time-series&quot;
      
    
    </summary>
    
      <category term="Economics" scheme="http://yoursite.com/categories/Economics/"/>
    
      <category term="Econometrics" scheme="http://yoursite.com/categories/Economics/Econometrics/"/>
    
      <category term="Time Series" scheme="http://yoursite.com/categories/Economics/Econometrics/Time-Series/"/>
    
    
      <category term="Econometrics" scheme="http://yoursite.com/tags/Econometrics/"/>
    
      <category term="Time Series" scheme="http://yoursite.com/tags/Time-Series/"/>
    
  </entry>
  
  <entry>
    <title>Refreshed Age of 23</title>
    <link href="http://yoursite.com/2020/03/29/PJ_02%20Refreshed%20Age%20of%2023/"/>
    <id>http://yoursite.com/2020/03/29/PJ_02 Refreshed Age of 23/</id>
    <published>2020-03-29T04:00:00.000Z</published>
    <updated>2020-03-30T20:23:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>I have thought how I should summarize my age of 23 for a long time, because my experience is so diverse and colorful during this year that it is really difficult for me to abstract it in one word. But if I have to choose one, I will say it is a “refreshed” year, which is not only a summary from the hindsight, but also an expectation for the future.</p><p>After accepting the offer from the Master of Financial Engineering at NYU, I led a relatively relieved life. It had drove me almost 3 years, and to some extent, I partially achieved the dream from a very young age. But such is a human nature that we always want more. There was an inner voice telling me that I should do something so as not to waste the precious time: therefore, I applied for an economic research assistant and several internship at Beijing and Shanghai. Although they are quite different directions from the hindsight, I was thinking that if I went to the NYU program, I would prefer to continue pursuing a doctoral degree. Fortunately enough, I got the reply from the PhD candidate Franklin Qian first, and started to do the research assistant remotely. He has been patient and instructing me in hands for lots of tasks, and I am still assisting him for his papers now. </p><p>Here, I have to thank him for re-inspiring my academic passion and showing me a clear plan of pursuing academic career. The academic stuff, especially the empirical jobs, is really time consuming and I had spent a lot of time on the first stage of hand collecting. But after that, I had the access to more analyzing works, including building dataset by different tools, imputing a variable, setting up servers and et cetera. I used to consider myself as a meticulous guy when dealing with the arranging and analyzing tasks, whatever they are academic or industrial. However, after I did the research with him, I found there were much improvement I could make, from the thinking flow to the project management. The next stage is more about analysis work, I hope I can handle it and make more progress. </p><p>Considering that research tasks were remote, I started another plan to travel around the China, especially the southern China. There were several meeting held by NYU Tandon School in Beijing, Shanghai and Guangzhou in April and I needed to apply for the US visa in one of these cities. Coincidently, Derek Zhang, my undergraduate roommate, was working at Guangzhou and invited me to live with him. In total I traveled for almost 2 months. I went to Hangzhou, Changsha before I arrived at Guangzhou. During my stay with Derek Zhang, who was living in a serviced apartment in Zhujiang New Town, I also visited Shenzhen, Dongguan, Zhuhai, Macao and Hongkong. Actually, it was the happiest time I have ever had, not only playing with many old friends in XMU, DKU and high school, but trying a lot of new stuff for the first time: going to the hip-hop festival and concert well-known for rappers, riding around SongShan Lake, playing role detective game, watching football games of Evergrande Football Club, attending a seminar in other’s school, gambling and enjoy the fantastic atmosphere in Macao, enjoying the beauty before a social movement and experiencing the narrow dwelling in HongKong. I really appreciate that Derek Zhang shared his apartment with me which helped me save a lot of money.</p><p>Before I went back to Zhengzhou, I also stopped by Xiamen, Fuzhou and Shanghai to visit teachers and friends in XMU, as well as previous bosses I have cooperated with. Chatting with Arielle and her boyfriend (now her fiance), having dinner with Huan and lunch with Charlotte, I learned quite a lot from them. Because Derek persuaded me to have a travel in the U.K, after receiving the passport from the U.S. Embassy, I need go to Beijing for the U.K. visa. At Beijing, I lived with Endong’s apartment, near Wangjing, and met with the instructor of my education agency and old friends in DKU, XMU and high school.</p><p>Actually, during this period, I had spent a lot of time with my families. After I came back from Shanghai and before I went to Beijing, my father had to be in hospital and a surgery was necessary. Then during that week, our family members took turns to take care of him. Fortunately, he recovered and left the hospital soon. I also went back to Luoyang to celebrate my grandma’s birthday together with other relations. Basically, during the spring and early summer before I went aboard, I tried to say goodbye to most of my friends, instructors, families because I was aware that it is harder and harder for us to reunion again as time flies. I have to cherish these moments.</p><p>At the mid of July, I am on the journey of new exploration. My mother sent me to Xi’an Airport and I flied to London first, with transition at Helsinki, Finland. July, 23rd Qinhao Min picked me up at Heathrow airport and Derek Zhang joined us the next day. We went to the most famous places of interest in London, York, Edinburgh, Manchester City, Nottingham, Cambridge, Oxford. (I have uploaded our traveling photos on Instagram). I watched The Tempest performed by Shakespeare’s Rose Theater in York. it was the first time for me to enjoy Drama in English. I also watched the The Phantom of the Opera at Her Majesty’s Theater, which was really amazing.  I plan to arrange my travel notes in England and Scotland if I am free. I will update it in the future.</p><p>I spent 10 days in U.K. but I cannot say that I went abroad actually, because I was just with Haomin and Derek in U.K. We talked in Chinese and there was little cross-culture shock. However, as soon as I started to walk towards Security Check before on board, I realized that I had to face all the unknown situation all by myself. A little fear but more curiosity drove my body. When I sat down at the departure lounge, a sense of loneliness sprout in my heard, because there was no Chinese face, even little Asian face in my sight. But a black man and her wife sitting beside me warmed me a lot during the flight. It is my honor to meet and have a great chat with them.</p><p>On August 1st, I arrived at New York John F. Kennedy airport and started a new life. I met Shan Hui first and applied for cellphone number, Bank account, the Internet connection and the insurance. And most important thing is to settle down in the new apartment. (My roommates, besides Shan Hui, are Jiawei Wei, Yuxiao Cai.) The life in New York is colorful but expensive. It cost more than 6000 dollars each month for our 4 roommates in total. Moreover, it takes more than 1900 dollars for each credit in NYU. I should take the most advantage of the resource I can access, because the money is from my family.</p><p>The biggest challenge in NYU was the mathematics and quantitative stuff. The stochastic processes and stochastic calculus, coupled with Object Oriented Programming in C++ drove me crazy. But these were not the worst. I selected the class held by Peter Carr, the director of my department, on impulse. The outcome proved it was the terrible decision: I just collected all difficult subjects in the same semester. Although there are other excuses, to be brief, I ruined it. During the rest semesters, I have to try to my best to promote my grade point average. But every coin has two sides: I enriched myself in mathematics during the 4 months.</p><p>In the winter holiday, Tianhao Shen, Yifei Zhang and I traveled to Los Vegas and several places in California. Tianhao picked me up at New York and we drove to Boston to meet Yifei. Then we three flied to Los Vegas, with transition at Salt Lake City. We lived at Caesar and I went to casino again after 7 months. But this time, I didn’t gamble. even the slot machine. However, the steak in Gordon Ramsay’s restaurant and strip show excited me a lot. After having the most famous buffet all around the world, we flied to Los Angeles and started a road trip. Here, we had only one driver, Tianhao. Yifei and  I owed him a lot, even if we came across a small car accident during the ride from Los Angeles to San Francisco. We three spent the Christmas eve at Los Angeles and New year eve at San Francisco. I will never forget this amazing trip. </p><p>After coming back to New York, it was still in the winter holiday. It is the first time for me to spend Chinese traditional new year eve by myself, but I also met a lot of old and new friends during these time. NYC is where amazing happens, because you can also meet people out of your expectation. However, during the same time, corona-virus outbreak at Wuhan, and NYC would never forecast itself would be stuck by corona-virus and the most number of corona-virus cases all over the U.S. in 2 months. And on my birthday, it is just at the peak of corona-virus crisis. I have continuously stayed home for 2 months and only went out twice during the last 4 months. I hope NYC and everyone can be going well and survive it.</p><p>These days, a famous description about destiny, which is originally expressed in Chinese, always occurs to me:</p><blockquote><p>When you are old, looking back on your life, you will find that: when you decide to go abroad for study, when you start the first career, when you fall in love with someone, and when you get married, it is actually a really big change in the life. But standing at the intersection, you will never realize how complicated it is. On the day of making the decisions, in your diary, it was probably quite dull and ordinary. At that time, you thought it was an ordinary day in life.</p></blockquote><p>I cannot agree with it more when I was typing down these words, especially reviewing the last year. I realize and believe that the last year and the next several years means a lot to me. And this is where the word “refreshed” comes from: I wish I have the ability to keep myself refreshed —— whatever difficulties I will come across, however ridiculous thought I will have, whenever I am at rock bottom, I can always regain the strength and energy to move on. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I have thought how I should summarize my age of 23 for a long time, because my experience is so diverse and colorful during this year tha
      
    
    </summary>
    
      <category term="Thoughts" scheme="http://yoursite.com/categories/Thoughts/"/>
    
      <category term="Personal Journals" scheme="http://yoursite.com/categories/Thoughts/Personal-Journals/"/>
    
    
      <category term="Journal" scheme="http://yoursite.com/tags/Journal/"/>
    
      <category term="Annual Letter" scheme="http://yoursite.com/tags/Annual-Letter/"/>
    
  </entry>
  
  <entry>
    <title>Bash Basics</title>
    <link href="http://yoursite.com/2020/03/17/Bash%20basics/"/>
    <id>http://yoursite.com/2020/03/17/Bash basics/</id>
    <published>2020-03-17T04:00:00.000Z</published>
    <updated>2020-03-18T16:17:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><h3 id="1-options"><a href="#1-options" class="headerlink" title="1. options"></a>1. options</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## list the files in time order</span></span><br><span class="line">ls -alhtr</span><br><span class="line"><span class="comment"># -a: all files</span></span><br><span class="line"><span class="comment"># -d: show as a directory, don't show the sub-files</span></span><br><span class="line"><span class="comment"># -l: long information: permission, owner, sizes</span></span><br><span class="line"><span class="comment"># -l --full-time: full time </span></span><br><span class="line"><span class="comment"># -l --full-time --time=atime/ctime/mtime</span></span><br><span class="line"><span class="comment"># -r: recursive</span></span><br><span class="line"><span class="comment"># -h: human-readable </span></span><br><span class="line"><span class="comment"># -si: similar to -h</span></span><br><span class="line"><span class="comment"># -t: order by time</span></span><br><span class="line"><span class="comment"># -v: order by version</span></span><br><span class="line"><span class="comment"># -F or -p: seperate the folders and files</span></span><br><span class="line"><span class="comment">#### mtime: the latest revised time</span></span><br></pre></td></tr></table></figure><h3 id="2-filter"><a href="#2-filter" class="headerlink" title="2. filter"></a>2. filter</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls <span class="built_in">test</span>*</span><br><span class="line">ls D*</span><br><span class="line">ls -d */</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># filter to show the files</span></span><br><span class="line">ls -F |grep -v /</span><br><span class="line"><span class="comment"># filter to show the directories</span></span><br><span class="line">ls -F |grep /$</span><br></pre></td></tr></table></figure><h3 id="3-order"><a href="#3-order" class="headerlink" title="3. order"></a>3. order</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lt</span><br></pre></td></tr></table></figure><h3 id="4-useful-link"><a href="#4-useful-link" class="headerlink" title="4. useful link:"></a>4. useful link:</h3><p><a href="https://www.cnblogs.com/sparkdev/p/7476005.html" target="_blank" rel="noopener">linux ls命令</a></p><p><a href="https://www.cnblogs.com/peida/archive/2012/10/23/2734829.html" target="_blank" rel="noopener">ls命令</a></p><h1 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h1><h2 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls | grep</span><br></pre></td></tr></table></figure><h1 id="Check-files"><a href="#Check-files" class="headerlink" title="Check files"></a>Check files</h1><h2 id="Vim"><a href="#Vim" class="headerlink" title="Vim"></a>Vim</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim test.py</span><br><span class="line">vim ./test.py</span><br></pre></td></tr></table></figure><h2 id="head"><a href="#head" class="headerlink" title="head"></a>head</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head test.py</span><br></pre></td></tr></table></figure><h1 id="Process-Management"><a href="#Process-Management" class="headerlink" title="Process Management"></a>Process Management</h1><h2 id="top-htop"><a href="#top-htop" class="headerlink" title="top/htop"></a>top/htop</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htop</span><br></pre></td></tr></table></figure><h2 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep ygnmax</span><br><span class="line"><span class="comment"># ps = process status</span></span><br><span class="line"><span class="comment"># a = show processes for all users</span></span><br><span class="line"><span class="comment"># u = display the process's user/owner</span></span><br><span class="line"><span class="comment"># x = also show processes not attached to a terminal</span></span><br></pre></td></tr></table></figure><h1 id="Environment-Management"><a href="#Environment-Management" class="headerlink" title="Environment Management"></a>Environment Management</h1><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><h3 id="1-install"><a href="#1-install" class="headerlink" title="1. install"></a>1. install</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># modules installation dir</span></span><br><span class="line">INSTALL_PATH=<span class="variable">$&#123;HOME&#125;</span>/opt/modules-4.2.1/</span><br><span class="line"></span><br><span class="line">tar -xvf modules-4.2.1.tar</span><br><span class="line"></span><br><span class="line"><span class="comment"># enter modules folder</span></span><br><span class="line"><span class="built_in">cd</span> modules-4.2.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># install modules</span></span><br><span class="line">./configure --prefix=<span class="variable">$&#123;INSTALL_PATH&#125;</span></span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h3 id="2-usage"><a href="#2-usage" class="headerlink" title="2. usage"></a>2. usage</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># check the available software</span></span><br><span class="line">module avail</span><br><span class="line">module avail stata</span><br><span class="line"></span><br><span class="line"><span class="comment"># load software</span></span><br><span class="line">module load statamp/15</span><br><span class="line"></span><br><span class="line"><span class="comment"># list loaded software</span></span><br><span class="line">module list</span><br><span class="line"></span><br><span class="line"><span class="comment"># unload software</span></span><br><span class="line">module unload statamp/15</span><br></pre></td></tr></table></figure><h3 id="3-useful-Link"><a href="#3-useful-Link" class="headerlink" title="3. useful Link"></a>3. useful Link</h3><p><a href="http://modules.sourceforge.net/" target="_blank" rel="noopener">Environment Modules</a></p><p><a href="https://zhuanlan.zhihu.com/p/50725572" target="_blank" rel="noopener">Environment Modules 简明教程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;List&quot;&gt;&lt;a href=&quot;#List&quot; class=&quot;headerlink&quot; title=&quot;List&quot;&gt;&lt;/a&gt;List&lt;/h1&gt;&lt;h2 id=&quot;list&quot;&gt;&lt;a href=&quot;#list&quot; class=&quot;headerlink&quot; title=&quot;list&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="Computer Science" scheme="http://yoursite.com/categories/Computer-Science/"/>
    
      <category term="Tools" scheme="http://yoursite.com/categories/Computer-Science/Tools/"/>
    
      <category term="Bash" scheme="http://yoursite.com/categories/Computer-Science/Tools/Bash/"/>
    
    
      <category term="Bash" scheme="http://yoursite.com/tags/Bash/"/>
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Conda Basics</title>
    <link href="http://yoursite.com/2020/03/17/Conda%20Install/"/>
    <id>http://yoursite.com/2020/03/17/Conda Install/</id>
    <published>2020-03-17T04:00:00.000Z</published>
    <updated>2020-03-18T16:00:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Conda-commands"><a href="#Conda-commands" class="headerlink" title="Conda commands"></a>Conda commands</h1><h2 id="1-install"><a href="#1-install" class="headerlink" title="1. install"></a>1. install</h2><h2 id="2-Setting-up-Anaconda-Environments"><a href="#2-Setting-up-Anaconda-Environments" class="headerlink" title="2. Setting up Anaconda Environments"></a>2. Setting up Anaconda Environments</h2><h3 id="2-1-set-up"><a href="#2-1-set-up" class="headerlink" title="2.1 set up"></a>2.1 set up</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># list all available version in anaconda</span></span><br><span class="line">conda search <span class="string">"^python$"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># to create a new environment (the latest)</span></span><br><span class="line">conda create --name gy_env python=3</span><br><span class="line"><span class="comment"># to create a specific version environment</span></span><br><span class="line">conda create --n gy_env36 python=3.6</span><br><span class="line"></span><br><span class="line"><span class="comment"># activate the new environment</span></span><br><span class="line">conda activate gy_env</span><br><span class="line"></span><br><span class="line"><span class="comment"># verify the version of Python</span></span><br><span class="line">python --version</span><br></pre></td></tr></table></figure><h3 id="2-2-activate-deactivate-update"><a href="#2-2-activate-deactivate-update" class="headerlink" title="2.2 activate / deactivate / update"></a>2.2 activate / deactivate / update</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># activate</span></span><br><span class="line">conda activate gy_env</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="built_in">source</span> activate gy_env</span><br><span class="line"></span><br><span class="line"><span class="comment"># deactive</span></span><br><span class="line">conda deactivate gy_env</span><br><span class="line"><span class="comment"># update the version (from 3.6.1 to 3.6.2)</span></span><br><span class="line">conda update python</span><br><span class="line"><span class="comment"># environment information</span></span><br><span class="line">conda info --envs</span><br></pre></td></tr></table></figure><h3 id="2-3-install-packages"><a href="#2-3-install-packages" class="headerlink" title="2.3 install packages"></a>2.3 install packages</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># install</span></span><br><span class="line">conda install --name gy_env36 numpy</span><br><span class="line"><span class="comment"># when creating:</span></span><br><span class="line">conda create --name gy_env python=3 numpy</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove</span></span><br><span class="line">conda remove --name gy_env36 --all</span><br></pre></td></tr></table></figure><h2 id="3-Update-Anaconda"><a href="#3-Update-Anaconda" class="headerlink" title="3. Update Anaconda"></a>3. Update Anaconda</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda update conda</span><br><span class="line">conda update -n base -c defaults conda</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conda update anaconda</span><br></pre></td></tr></table></figure><h2 id="4-Uninstall-Anaconda"><a href="#4-Uninstall-Anaconda" class="headerlink" title="4. Uninstall Anaconda"></a>4. Uninstall Anaconda</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># start with "anaconda-clean" to remove configuration files</span></span><br><span class="line">conda install anaconda-clean</span><br><span class="line"><span class="comment"># then run the "anaconda-clean", this will create a backup folder called .anaconda_backup</span></span><br><span class="line">anaconda-clean</span><br><span class="line"><span class="comment"># remove the entire diretory</span></span><br><span class="line">rm -rf ~/anaconda3</span><br><span class="line"><span class="comment"># remove the PATH line</span></span><br><span class="line">vim ~/.bashrc</span><br><span class="line"><span class="comment"># Delete or comment out the following lines:</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">"/home/ygnmax/anaconda3/bin:<span class="variable">$PATH</span>"</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Conda-commands&quot;&gt;&lt;a href=&quot;#Conda-commands&quot; class=&quot;headerlink&quot; title=&quot;Conda commands&quot;&gt;&lt;/a&gt;Conda commands&lt;/h1&gt;&lt;h2 id=&quot;1-install&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="Computer Science" scheme="http://yoursite.com/categories/Computer-Science/"/>
    
      <category term="Tools" scheme="http://yoursite.com/categories/Computer-Science/Tools/"/>
    
      <category term="Conda" scheme="http://yoursite.com/categories/Computer-Science/Tools/Conda/"/>
    
    
      <category term="Anaconda" scheme="http://yoursite.com/tags/Anaconda/"/>
    
  </entry>
  
  <entry>
    <title>Operational Risk</title>
    <link href="http://yoursite.com/2020/03/13/Financial%20Risk%20Management%20Operational%20Risk/"/>
    <id>http://yoursite.com/2020/03/13/Financial Risk Management Operational Risk/</id>
    <published>2020-03-13T04:00:00.000Z</published>
    <updated>2020-03-13T13:35:46.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Operational-Risk"><a href="#Operational-Risk" class="headerlink" title="Operational Risk"></a>Operational Risk</h1><h2 id="What-is-Operational-Risk"><a href="#What-is-Operational-Risk" class="headerlink" title="What is Operational Risk"></a>What is Operational Risk</h2><p>The operations of a bank or financial institution refers to <strong>the mechanism by which these firms put their strategies into practice</strong> by employing professionals, developing processes, defining best practices and establishing the proper infrastructure (increasingly through the use of emerging technology to achieve strategic objectives.</p><p>Managing operational risk is a function of <strong>both internal and external processes</strong> related to cash and securities and managing client accounts and information. The approach must evolve along with changes in technology, markets and regulation.</p><p>More traditional monitoring in the form of periodic credit reviews and operational risks associated with transactional banking such as the segregation or safekeeping of client assets or data protection issues are critical risk monitoring functions</p><h3 id="People"><a href="#People" class="headerlink" title="People"></a>People</h3><ul><li><strong>Key person risk</strong> refers to any institution which relies heavily on one individual,<br>whether that be within senior management or operations</li><li><strong>Rogue employee or trader risk</strong> will always remain a concern despite of enhanced and automated methods of managing monitoring employee activity</li></ul><h3 id="Processes"><a href="#Processes" class="headerlink" title="Processes"></a>Processes</h3><ul><li>Procedural breakdowns in processing and managing market and credit risk as well as meeting compliance and regulatory requirements can create competitive disadvantages or result in opportunity cost and/or actual losses</li><li>It is important to continually review controls and incentives in place, and adapt to a changing market and regulatory environment</li></ul><h3 id="Systems"><a href="#Systems" class="headerlink" title="Systems"></a>Systems</h3><ul><li><strong>Errors</strong> resulting from outdated systems, lack of systems integration and/or gaps<br>where human intervention is needed can raise costs and lower efficiency</li><li>Increasing use of technology, in particular artificial intelligence, robotics process<br>automation and machine learning techniques to eliminate manual, error prone repetitive processes among banks and financial institutions</li></ul><h2 id="Where-is-Operational-risk-from"><a href="#Where-is-Operational-risk-from" class="headerlink" title="Where is Operational risk from"></a>Where is Operational risk from</h2><h3 id="Market-Infrastructure"><a href="#Market-Infrastructure" class="headerlink" title="Market Infrastructure"></a>Market Infrastructure</h3><ul><li>Central Securities Depositories (Euroclear, Clearstream)</li><li>Global Payments Network (Fedwire, CHIPS, etc.)</li><li>Exchanges and Clearinghouses (NYSE, NASDAQ, CME, LCH, etc.)</li><li>Securities Financing Transactions (Repo)</li><li>Role of a Global Custodian in Managing Operational Risk</li></ul><h3 id="Internal-Operational-Risk-Management"><a href="#Internal-Operational-Risk-Management" class="headerlink" title="Internal Operational Risk Management"></a>Internal Operational Risk Management</h3><ul><li>Identification</li><li>Assessment</li><li>Measurement</li><li>Control and Mitigation</li><li>Monitoring and Reporting</li></ul><h3 id="CSD"><a href="#CSD" class="headerlink" title="CSD"></a>CSD</h3><p><strong>Shift from Decentralized Physical to Centralized Dematerialized Processing:</strong> Until the Paperwork Crisis of 1968 NYSE stock certificates were physically delivered until brokers were overwhelmed by high trade volumes Firms failed and the number of failed trades (if delivery did not occur within five days) soared The NYSE established the Central Certificate Service ( to transfer securities electronically, eliminate physical handling, and track shares held by NYSE members</p><p><strong>Central Securities Depositories</strong> are entities which record legal entitlements to<br>dematerialized securities and operate transaction settlement systems in those securities Major CSDs, include DTCC, Euroclear and Clearstream</p><ul><li><p><strong>DTCC (Depository Trust Clearing Corporation, formerly CCS)</strong> DTCC is owned and directed by its users It automates, standardizes, and streamlines capital markets transactions</p><ul><li>DTC (Depository Trust Corporation) provides clearance, settlement, and information services for equities, corporate and municipal bonds, unit investment trusts, government and mortgage backed securities, money market instruments, and over the counter derivatives</li><li>NSCC (National Securities Clearing Corporation) executes multilateral netting to manage transactions between mutual funds and insurance carriers and their respective investors</li><li>FICC (Fixed Income Clearing Corporation) provides clearing for fixed income securities, including Treasury securities and mortgage backed securities, including real time trade matching, clearing, risk management, and netting for trades in US government debt issues, including repurchase agreements or repos</li></ul></li><li><p><strong>Euroclear</strong></p></li><li><strong>Clearstream</strong></li></ul><h3 id="Payment-Networks"><a href="#Payment-Networks" class="headerlink" title="Payment Networks"></a>Payment Networks</h3><p><strong>SWIFT (Society for Worldwide Interbank Financial Telecommunication)</strong> is a cooperative utility messaging system formed in 1973 by over 200 banks headquartered in Belgium. In 1977 it replaced Telex technology with a messaging platform to validate and route standardized messages. Over 11 000 financial institutions in more than 200 countries now use SWIFT. As a secure financial messaging system, SWIFT does not perform funds transfer, clearing or settlement. SWIFT payment orders must be settled by correspondent accounts that institutions have with one other.</p><p><strong>Fedwire</strong> is a real time gross settlement funds transfer system operated by U S Federal Reserve Banks enabling financial institutions to electronically transfer funds between over 9 000 participants.</p><p><strong>Correspondent Banking</strong> Bilateral arrangement, often involving a reciprocal cross border relationship in multiple currencies. A correspondent banking arrangement involves one bank (the correspondent) providing accounts and related services, to another bank (the respondent), often including its affiliates.</p><h3 id="Exchanges-and-Clearinghouses"><a href="#Exchanges-and-Clearinghouses" class="headerlink" title="Exchanges and Clearinghouses"></a>Exchanges and Clearinghouses</h3><p><strong>Securities and derivatives exchanges</strong> provide a centralized location where securities are listed and traded by a restricted set of brokers who are members of an exchange; recordkeeping is dematerialized and based upon electronic communication networks.</p><p><strong>Alternative trading venues</strong> and systems including dark pools offer private means to conduct securities transactions These venues have faced increased scrutiny and disclosure (under Regulation ATS) given concerns over conflict of interest and other practices<br><strong>Central clearinghouses</strong> (CCPs) are centralized entities including CME and LCH which mutualize counterparty credit risk in the foreign exchange, interest rate, equity, credit, commodity and weather derivative markets in which they operate CCPs aim to reduce settlement risk via several measures</p><ul><li>Net offsetting trades between multiple counterparties</li><li>Require collateral (margin) deposits</li><li>Provide independent valuation of trades and collateral</li><li>Monitor creditworthiness of member firms, and</li><li>Provide a guarantee fund used to cover losses exceeding a defaulting member’s collateral </li></ul><p><strong>Advantages of central counterparty clearing arrangements</strong> are greater risk transparency, lower processing costs, and clear rules in cases of member default Once a trade has been executed by two counterparties, they are novated to a clearinghouse which steps between trader clearing firms to assumes legal counterparty risk for the trade (a trade between members A and B become two trades A CCP and CCP B)</p><p><strong>Disadvantages</strong> of central clearing include the concentration of risk which was previously decentralized and distributed in the bilateral OTC model, the interdependency of CCPs, which are now have become crucial financial infrastructures following post crisis reform which forced the over the counter derivatives market into central clearing and the limited capital held by CCPs themselves</p><h3 id="Securities-Financing-Transactions-Repo"><a href="#Securities-Financing-Transactions-Repo" class="headerlink" title="Securities Financing Transactions (Repo)"></a>Securities Financing Transactions (Repo)</h3><h3 id="Global-Custodian"><a href="#Global-Custodian" class="headerlink" title="Global Custodian"></a>Global Custodian</h3><p><strong>Global custody and fund services</strong> providers offer a range of financial services associated with the safekeeping of financial assets including the following:</p><ul><li>Hold in safekeeping securities such as domestic and foreign stocks, bonds, commodities and cash</li><li>Facilitate settlement of purchases/sales and deliveries in/out of securities and currency</li><li>Support asset income collection (regular and special dividends, bond coupons, maturities) and administer related tax withholding documents and foreign tax reclamation</li><li>Provide corporate action services on securities held such as proxy voting, stock dividends, stock splits, business combinations ( tender offers, bond calls, etc</li><li>Offer securities lending services</li><li>Maintain currency cash bank accounts manage cash and perform foreign exchange transactions</li><li>Perform accounting services such as NAV reporting for mutual funds, accounting services and complex sub accounting services for pension funds</li></ul><p><strong>Operational challenges</strong> outsourced by investors to custodians include the following:</p><ul><li><strong>Active subcustodian management</strong>: Custodians contract with local banks as agents, performing initial and ongoing due diligence on financial strength, custody expertise and capacity, technology, management and infrastructure, ties with local market entities, income and corporate action capabilities, internal/external audit results, contingency plans, insurance coverage and tax expertise</li><li><strong>Assist in new market expansion Clients considering expansion</strong> to a new market tap custody bank expertise on market structure, requirements and regulation When a custodian opens a new market to clients, network market managers work with local market representatives to understand the market and advocate for infrastructure changes to make markets more acceptable to foreign investors</li><li><strong>Asset segregation and ringfencing</strong>: Custodians conduct periodic legal reviews of recoverability of securities held on behalf of clients in the event of the bankruptcy of the subcustodian, maintaining omnibus and segregated cash and securities accounts in the name of the bank separate from subcustodian assets where possible</li></ul><h2 id="Manage-Operational-Risk"><a href="#Manage-Operational-Risk" class="headerlink" title="Manage Operational Risk"></a>Manage Operational Risk</h2><h3 id="Five-steps"><a href="#Five-steps" class="headerlink" title="Five steps"></a>Five steps</h3><p><strong>Identification</strong></p><p><strong>Assessment</strong></p><p><strong>Measurement</strong></p><p><strong>Control and Mitigation</strong></p><p><strong>Monitoring and Reporting</strong></p><p><strong>Compliance risk</strong>: Failure to comply with legal or regulatory obligations, codes of conduct and standards of self regulatory organizations applicable to the business activities of the Firm</p><ul><li><p>use the outer communication system (like whatsapp)</p></li><li><p>send restricted data from work desktop to an external domain</p></li></ul><p><strong>Conduct risk</strong>: Risk that an action (or inaction) by an employee or employees could lead to unfair client or customer outcomes, impact the integrity of the markets in which the Firm operates, or compromise the Firm’s reputation.</p><p><strong>Legal risk</strong>: Loss primarily caused by actual or alleged failure to meet legal obligations that arise from the rule of law in jurisdictions in which the Firm operates, agreements with clients and customers, and products and services offered by the Firm.</p><p><strong>Estimations and Model Risk:</strong> Potential for adverse consequences from decisions based on incorrect or misused estimation outputs</p><p><strong>Cybersecurity risk</strong> The Firm devotes significant resources to protecting and continuing to improve the security of the Firm’s computer systems, software, networks and other technology assets<br><strong>Business and technology resiliency risk</strong>: Business disruptions can occur due to forces beyond the Firm’s control such as severe weather, power or telecommunications loss, flooding, transit strikes, terrorist threats or infectious disease The safety of employees and customers is the highest priority. The Firm’s global resiliency program is intended to enable the recovery of critical business functions and supporting assets ( technology and facilities) in the event of a business interruption </p><p><strong>Payment fraud risk</strong>: Payment fraud risk is the risk of external and internal parties unlawfully obtaining personal monetary benefit through misdirected or otherwise improper payment.</p><p><strong>Third party outsourcing risk</strong>: To identify and manage the operational risk inherent in outsourcing.</p><h2 id="Quantifying-Operating-Risk"><a href="#Quantifying-Operating-Risk" class="headerlink" title="Quantifying Operating Risk"></a>Quantifying Operating Risk</h2><p>Expected versus Unexpected Loss</p><p><strong>Basic Indicator Approach</strong></p><p>Simplest form for banks without significant international operations Banks using the BIA must hold capital for operational risk equal to the average over the previous three years of a fixed percentage α of positive annual gross income (excluding year where annual gross income is negative or zero):</p><script type="math/tex; mode=display">K_{BIA}=\frac{\sum GI_{1,2,\cdots,n}*\alpha}{n}</script><p><strong>Standard Approach</strong></p><p>This methodology used for internationally active institutions divides bank activities into corporate finance, sales trading, retail, commercial banking, payment settlement, agency services, asset management, and retail brokerage Gross income serves as a proxy for the scale of the business and operational risk exposure for each segment Capital charges are calculated by multiplying gross income by a β factor which defines the relationship between industry wide operational risk loss experience and gross income</p><script type="math/tex; mode=display">K_{\text{TSA}}=\frac{\sum_{\text{years}1-3}\max(\sum_{i=1}^{8}GI_{i}*\beta_i)}{3}</script><p>Standardized Approach Beta Factors The beta factors are a fixed percentage, set by the Committee, relating the level of required capital to the level of the gross income for each of the eight business lines as follows:</p><div class="table-container"><table><thead><tr><th>Business Line</th><th>Beta Factor</th><th>NI Average</th></tr></thead><tbody><tr><td>Corporate Finance (β1)</td><td>18%</td><td>20</td></tr><tr><td>Sales &amp; Trading (β2)</td><td>18%</td><td>0</td></tr><tr><td>Retail Banking (β3)</td><td>12%</td><td>20</td></tr><tr><td>Commercial Banking (β4)</td><td>15%</td><td>25</td></tr><tr><td>Payment &amp; Settlement (β5)</td><td>18%</td><td>15</td></tr><tr><td>Agency Services (β6)</td><td>15%</td><td>10</td></tr><tr><td>Asset Management (β7)</td><td>12%</td><td>25</td></tr><tr><td>Retail Brokerage (β8)</td><td>12%</td><td>15</td></tr></tbody></table></div><p>Example:</p><p>Under BIA, $\alpha = 15\%$</p><script type="math/tex; mode=display">K_{BIA}=130*15\% = 19.5</script><p>Under SA</p><script type="math/tex; mode=display">K_{KSA}=\frac{\sum_{\text{years}1-3}\max(\sum_{i=1}^{8}GI_{i}*\beta_i)}{3} = 18.75</script><p><strong>Advanced Management Approach (AMA)</strong></p><h2 id="Operational-Risk-Mitigation-and-Control"><a href="#Operational-Risk-Mitigation-and-Control" class="headerlink" title="Operational Risk Mitigation and Control"></a>Operational Risk Mitigation and Control</h2><p><strong>Appetite</strong></p><p><strong>Existing Business</strong></p><p><strong>New Business</strong></p><p><strong>Build or Buy and Third-Party Risks</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Operational-Risk&quot;&gt;&lt;a href=&quot;#Operational-Risk&quot; class=&quot;headerlink&quot; title=&quot;Operational Risk&quot;&gt;&lt;/a&gt;Operational Risk&lt;/h1&gt;&lt;h2 id=&quot;What-is-O
      
    
    </summary>
    
      <category term="Economics" scheme="http://yoursite.com/categories/Economics/"/>
    
      <category term="Finance" scheme="http://yoursite.com/categories/Economics/Finance/"/>
    
      <category term="Risk Management" scheme="http://yoursite.com/categories/Economics/Finance/Risk-Management/"/>
    
    
      <category term="Risk Management" scheme="http://yoursite.com/tags/Risk-Management/"/>
    
      <category term="NYU" scheme="http://yoursite.com/tags/NYU/"/>
    
      <category term="FRM" scheme="http://yoursite.com/tags/FRM/"/>
    
  </entry>
  
  <entry>
    <title>Parameter Estimation</title>
    <link href="http://yoursite.com/2020/03/12/Statistics%20Parameter%20Estimation/"/>
    <id>http://yoursite.com/2020/03/12/Statistics Parameter Estimation/</id>
    <published>2020-03-12T04:00:00.000Z</published>
    <updated>2020-04-03T14:24:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Estimator"><a href="#Estimator" class="headerlink" title="Estimator"></a>Estimator</h1><h2 id="Criterion"><a href="#Criterion" class="headerlink" title="Criterion"></a>Criterion</h2><h3 id="unbiased"><a href="#unbiased" class="headerlink" title="unbiased"></a>unbiased</h3><p> For $\hat{\theta}$ which is the estimation of $\theta$, </p><script type="math/tex; mode=display">E_{\theta}(\hat{\theta})=\theta</script><h3 id="effectiveness"><a href="#effectiveness" class="headerlink" title="effectiveness"></a>effectiveness</h3><p>Assume $\hat{\theta_1}$ and $\hat{\theta_2}$ are both unbiased estimation, for $\forall \theta \in \Theta$,</p><script type="math/tex; mode=display">D(\hat{\theta_1}) \leq D(\hat{\theta_2})</script><p>then $\hat{\theta_1}$ is more effective than $\hat{\theta_2}$.</p><h3 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h3><p>For $\hat{\theta},$ $\forall ~ \theta \in \Theta$</p><script type="math/tex; mode=display">\lim\limits_{n \to \infty}P\{|\hat{\theta}-\theta|<\epsilon\}=1</script><h2 id="Moment-Estimation"><a href="#Moment-Estimation" class="headerlink" title="Moment Estimation"></a>Moment Estimation</h2><p>$ A<em>k = \frac{1}{n}\sum\limits</em>{i=1}^{n}X_i^k$ is convergent to $\mu_k$ by probability, where $\mu_k$ is k-order moment.</p><p>If there are $k$ parameters ($\theta_1, \theta_2,\cdots,\theta_k$), then we could compute $k$ order moment estimation:</p><script type="math/tex; mode=display">\begin{cases}\mu_1 &=& \mu_1(\theta_1, \theta_2,\cdots,\theta_k) \\\mu_2 &=& \mu_2(\theta_1, \theta_2,\cdots,\theta_k) \\&\vdots& \\\mu_2 &=& \mu_2(\theta_1, \theta_2,\cdots,\theta_k) \\\end{cases}</script><h2 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum Likelihood Estimation"></a>Maximum Likelihood Estimation</h2><h3 id="Likelihood-Function"><a href="#Likelihood-Function" class="headerlink" title="Likelihood Function"></a>Likelihood Function</h3><script type="math/tex; mode=display">L(\theta)=L(x_1, x_2, \cdots, x_n;\theta)=\prod\limits_{i=1}^{n}p(x_i;\theta), \theta\in \Theta</script><h3 id="Log-Likelihood-Function"><a href="#Log-Likelihood-Function" class="headerlink" title="Log Likelihood Function"></a>Log Likelihood Function</h3><script type="math/tex; mode=display">\ln L(\theta) =\ln\prod\limits_{i=1}^{n}p(x_i;\theta) = \sum_{i=1}^{n} \ln p(x_i;\theta), \theta\in \Theta</script><p>Example:</p><p>Assume $X\sim N(\mu,\sigma^2)$, $x_1, x_2, \cdots, x_n$ are samples, $\mu$ and $\sigma$ are unknown.</p><script type="math/tex; mode=display">\begin{eqnarray*}L(\mu, \sigma^2) &=& \prod_{i=1}^{n}\frac{1}{\sqrt{2\pi} \sigma}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}} \\&=& \frac{1}{(\sqrt{2\pi} \sigma)^n}e^{-\frac{1}{2\sigma^2}\sum\limits_{i=1}^{n}(x_i-\mu)^2} \\\ln L(\mu, \sigma^2) &=& -\frac{n}{2} \ln(2\pi)-\frac{n}{2} \ln\sigma^2-\frac{1}{2\sigma^2}\sum\limits_{i=1}^{n}(x_i-\mu)^2\end{eqnarray*}</script><p>Compute the partial derivatives:</p><script type="math/tex; mode=display">\begin{eqnarray*}\frac{\partial}{\partial\mu}\ln L &=& \frac{1}{\sigma}\left(\sum_{i=1}^{n} x_i-n\mu\right) = 0\\\frac{\partial}{\partial\sigma^2}\ln L &=& -\frac{n}{2\sigma^2}+\frac{1}{2(\sigma^2)^2}\sum_{i=1}^{n}(x_i-\mu)^2 = 0  \\\end{eqnarray*}</script><p>We can solve</p><script type="math/tex; mode=display">\mu = \frac{1}{n}\sum_{i=1}^{n}x_i = \bar{x} \\\sigma^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i-\mu)^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Estimator&quot;&gt;&lt;a href=&quot;#Estimator&quot; class=&quot;headerlink&quot; title=&quot;Estimator&quot;&gt;&lt;/a&gt;Estimator&lt;/h1&gt;&lt;h2 id=&quot;Criterion&quot;&gt;&lt;a href=&quot;#Criterion&quot; class
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/"/>
    
      <category term="Classic Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/Classic-Statistics/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/tags/Statistics/"/>
    
      <category term="Stochastic" scheme="http://yoursite.com/tags/Stochastic/"/>
    
  </entry>
  
  <entry>
    <title>Normal Sample</title>
    <link href="http://yoursite.com/2020/03/12/Statistics%20normal%20sample/"/>
    <id>http://yoursite.com/2020/03/12/Statistics normal sample/</id>
    <published>2020-03-12T04:00:00.000Z</published>
    <updated>2020-03-12T15:39:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Normal-Sample"><a href="#Normal-Sample" class="headerlink" title="Normal Sample"></a>Normal Sample</h1><h2 id="Normal-Distribution-Additivity"><a href="#Normal-Distribution-Additivity" class="headerlink" title="Normal Distribution Additivity"></a>Normal Distribution Additivity</h2><h3 id="Lemma-Convolution-Integral"><a href="#Lemma-Convolution-Integral" class="headerlink" title="Lemma: Convolution Integral"></a>Lemma: Convolution Integral</h3><h3 id="Additivity-of-normal-distribution"><a href="#Additivity-of-normal-distribution" class="headerlink" title="Additivity of normal distribution"></a>Additivity of normal distribution</h3><p>Suppose $X_i\sim N(\mu_i,\sigma_i^2)$, then </p><script type="math/tex; mode=display">Z = X_1 + X_2+\cdots+X_n</script><p>subjects to the same distribution, and $Z\sim N(\mu_1+\mu_2+\cdots +\mu_n, \sigma_1^2+\sigma_2^2+\cdots+\sigma_n^2)$</p><p>Proof:</p><h2 id="Normal-Distribution-Sample"><a href="#Normal-Distribution-Sample" class="headerlink" title="Normal Distribution Sample"></a>Normal Distribution Sample</h2><h3 id="Mean-distribution"><a href="#Mean-distribution" class="headerlink" title="Mean distribution"></a>Mean distribution</h3><p>Suppose $X_i\sim N(\mu,\sigma^2)$, then </p><script type="math/tex; mode=display">\begin{eqnarray*}\bar{X} & \sim & N(\mu, \frac{\sigma^2}{n}) \\\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} & \sim & N(0,1)\end{eqnarray*}</script><h3 id="Variance-distribution-variance-sigma-2-is-unknown"><a href="#Variance-distribution-variance-sigma-2-is-unknown" class="headerlink" title="Variance distribution (variance $\sigma^2$ is unknown)"></a>Variance distribution (variance $\sigma^2$ is unknown)</h3><p>Suppose $X_i\sim N(\mu,\sigma^2)$, then </p><script type="math/tex; mode=display">\frac{(n-1)S^2}{\sigma^2} \sim\chi^2(n-1)</script><p>$S^2$ is dependent to $\bar{X}$.</p><h3 id="Mean-distribution-mean-mu-is-unknown"><a href="#Mean-distribution-mean-mu-is-unknown" class="headerlink" title="Mean distribution (mean $\mu$ is unknown)"></a>Mean distribution (mean $\mu$ is unknown)</h3><p>Suppose $X_i\sim N(\mu,\sigma^2)$, then </p><script type="math/tex; mode=display">\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}} \sim t(n-1)</script><p>Proof:</p><script type="math/tex; mode=display">\begin{eqnarray*}\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} & \sim & N(0,1) \\\frac{(n-1)S^2}{\sigma^2} & \sim & \chi^2(n-1) \\\frac{\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}}{\sqrt{\frac{(n-1)S^2}{\sigma^2(n-1)}}} &=& \frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}} \sim t(n-1)\end{eqnarray*}</script><h3 id="Compare-with-two-random-variables-variance-sigma-2-is-unknown"><a href="#Compare-with-two-random-variables-variance-sigma-2-is-unknown" class="headerlink" title="Compare with two random variables (variance $\sigma^2$ is unknown)"></a>Compare with two random variables (variance $\sigma^2$ is unknown)</h3><p>Suppose $X<em>1, X_2, \cdots, X</em>{n<em>1} \sim N(\mu_1,\sigma_1^2)$ and $Y_1, Y_2, \cdots, Y</em>{n_2} \sim N(\mu_2,\sigma_2^2)$ , $X_i$ and $Y_i$ are sample and independent to each other. $\bar{X}$ and $\bar{Y}$ are sample mean, $S_1^2$ and $S_2^2$ are sample  variance, then</p><script type="math/tex; mode=display">\frac{\frac{S_1^2}{S_2^2}}{\frac{\sigma_1^2}{\sigma_2^2}} \sim F(n_1-1,n_2-1)</script><h3 id="Compare-with-two-random-variables-mean-mu-is-unknown"><a href="#Compare-with-two-random-variables-mean-mu-is-unknown" class="headerlink" title="Compare with two random variables (mean $\mu $ is unknown)"></a>Compare with two random variables (mean $\mu $ is unknown)</h3><p>When $\sigma_1^2 = \sigma_2^2 =\sigma^2$, then</p><script type="math/tex; mode=display">\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim  t(n_1+n_2-2)</script><p>with $S_w^2 = \frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}$</p><p><strong>Proof:</strong></p><p>$\bar{X}-\bar{Y}\sim N(\mu_1-\mu_2,\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2})$</p><p>after standardizing:</p><script type="math/tex; mode=display">\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}} = \frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sigma\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim N(0,1)</script><p>For $\frac{(n_1-1)S_1^2}{\sigma_1^2} \sim\chi^2(n_1-1)$ and $\frac{(n_2-1)S_2^2}{\sigma_2^2} \sim\chi^2(n_2-1)$, then:  </p><script type="math/tex; mode=display">\frac{(n_1-1)S_1^2 +(n_2-1)S_2^2  }{\sigma^2} \sim\chi^2(n_1+n_2-2)</script><p>by dividing:</p><script type="math/tex; mode=display">\frac{\frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{\sigma\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}}{\sqrt{\frac{(n_1-1)S_1^2 +(n_2-1)S_2^2  }{\sigma^2(n_1+n_2-2)}}} = \frac{(\bar{X}-\bar{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t(n_1+n_2+2)</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Normal-Sample&quot;&gt;&lt;a href=&quot;#Normal-Sample&quot; class=&quot;headerlink&quot; title=&quot;Normal Sample&quot;&gt;&lt;/a&gt;Normal Sample&lt;/h1&gt;&lt;h2 id=&quot;Normal-Distribution-A
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/"/>
    
      <category term="Classic Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/Classic-Statistics/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/tags/Statistics/"/>
    
      <category term="Stochastic" scheme="http://yoursite.com/tags/Stochastic/"/>
    
  </entry>
  
  <entry>
    <title>Central Limit Theorem</title>
    <link href="http://yoursite.com/2020/03/11/Statistics%20CLT/"/>
    <id>http://yoursite.com/2020/03/11/Statistics CLT/</id>
    <published>2020-03-11T04:00:00.000Z</published>
    <updated>2020-03-11T17:44:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Central-Limit-Theorem"><a href="#Central-Limit-Theorem" class="headerlink" title="Central Limit Theorem"></a>Central Limit Theorem</h1><h2 id="IID-CLT"><a href="#IID-CLT" class="headerlink" title="IID CLT"></a>IID CLT</h2><p>For infinite independent random variable $X_1, X_2, …X_n, …$, which are from the identical distribution with the expectation $E(X_k) = \mu$, and variance $D(X_k) = \sigma^2$, then for $\forall ~ x$</p><script type="math/tex; mode=display">\lim_{n \to \infty} F_n(x)=\lim_{n \to \infty} P\left\{ \frac{\sum\limits_{k=1}^{n}X_k-n\mu}{\sqrt{n}\sigma} \leq x \right\} = \Phi(x)</script><p>where  $F<em>n(x)$ is the distribution function of $\frac{\sum\limits</em>{k=1}^{n}X_k-n\mu}{\sqrt{n}\sigma}$.</p><ul><li><p>The CLT implies that large iid experiment usually follows the normal distribution</p></li><li><script type="math/tex; mode=display">\begin{eqnarray*}\sum\limits_{k=1}^{n}X_k \sim N(n\mu, n\sigma^2) \\\frac{1}{n}\sum\limits_{k=1}^{n}X_k \sim N(\mu, \frac{\sigma^2}{n})\end{eqnarray*}</script></li><li><p>Here, the sum of random variable $\sum\limits_{k=1}^{n}X_k$ matters.</p></li></ul><h2 id="De-Moivre-Laplace-Theorem"><a href="#De-Moivre-Laplace-Theorem" class="headerlink" title="De Moivre-Laplace Theorem"></a>De Moivre-Laplace Theorem</h2><p>For infinite independent random variable $\eta_1, \eta_2, …\eta_n, …$, which are from the <strong>binomial distribution</strong> $b(n,p)$, then for $\forall ~ x$</p><script type="math/tex; mode=display">\lim_{n \to \infty} P\left\{ \frac{\eta_n-np}{\sqrt{np(1-p)}} \leq x \right\} = \Phi(x)</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Central-Limit-Theorem&quot;&gt;&lt;a href=&quot;#Central-Limit-Theorem&quot; class=&quot;headerlink&quot; title=&quot;Central Limit Theorem&quot;&gt;&lt;/a&gt;Central Limit Theorem&lt;/
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/"/>
    
      <category term="Classic Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/Classic-Statistics/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/tags/Statistics/"/>
    
      <category term="Stochastic" scheme="http://yoursite.com/tags/Stochastic/"/>
    
  </entry>
  
  <entry>
    <title>Law of Large Numbers</title>
    <link href="http://yoursite.com/2020/03/11/Statistics%20LLN/"/>
    <id>http://yoursite.com/2020/03/11/Statistics LLN/</id>
    <published>2020-03-11T04:00:00.000Z</published>
    <updated>2020-03-11T17:21:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Lemma-Chebyshev-Inequality"><a href="#Lemma-Chebyshev-Inequality" class="headerlink" title="Lemma: Chebyshev Inequality"></a>Lemma: Chebyshev Inequality</h1><p>For $E(X) = \mu$ and $D(x) = \sigma^2$, then</p><script type="math/tex; mode=display">p\{| X-\mu| \geq \epsilon \} \leq\frac{\sigma^2}{\epsilon^2}</script><p>Proof:</p><script type="math/tex; mode=display">\begin{eqnarray*}p\{| X-\mu| \geq \epsilon \} &=& \int_{|x-\mu|\geq\epsilon}f(x)dx \\&\leq& \int_{|x-\mu|\geq\epsilon} \frac{|x-\mu|^2}{\epsilon^2} f(x)dx \\&\leq& \frac{1}{\epsilon^2}\int_{-\infty}^{\infty} (x-\mu)^2 f(x)dx \\&=& \frac{\sigma^2}{\epsilon^2}\end{eqnarray*}</script><p>which also implies</p><script type="math/tex; mode=display">p\{| X-\mu| < \epsilon \} \geq 1- \frac{\sigma^2}{\epsilon^2}</script><h1 id="Law-of-Large-Numbers"><a href="#Law-of-Large-Numbers" class="headerlink" title="Law of Large Numbers"></a>Law of Large Numbers</h1><h2 id="Khinchin-LLN"><a href="#Khinchin-LLN" class="headerlink" title="Khinchin LLN"></a>Khinchin LLN</h2><p>For infinite independent random variable $X_1, X_2, …$, which are from the identical distribution with the expectation $E(x_k) = \mu$, then for $\forall ~ \epsilon$</p><script type="math/tex; mode=display">\lim_{n \to \infty}P\left\{ \left| \frac{1}{n}\sum_{k=1}^{n}X_k-\mu \right| <\epsilon\right\} = 1</script><p>When the $n$ is close to positive infinity, $\frac{1}{n}\sum_{k=1}^{n}X_k$ is close to $\mu$, which is the expectation of $X$ </p><p>Proof:</p><p>Assume the variance exist $D(X) = \sigma^2$, then</p><script type="math/tex; mode=display">\begin{eqnarray*}E\left(\frac{1}{n}\sum_{k=1}^nX_k\right) &=& \frac{1}{n}\sum_{k=1}^nE(X_k) \\&=& \frac{1}{n}\times n\mu \\&=& \mu\end{eqnarray*}</script><script type="math/tex; mode=display">\begin{eqnarray*}D\left(\frac{1}{n}\sum_{k=1}^nX_k\right) &=& \frac{1}{n^2}\sum_{k=1}^nD(X_k) \\&=& \frac{1}{n^2}\times n\sigma^2 \\&=& \frac{\sigma^2}{n}\end{eqnarray*}</script><p>use the Chebyshev Inequity:</p><script type="math/tex; mode=display">\begin{eqnarray*}1 \geq  P\left\{ \left| \frac{1}{n}\sum_{k=1}^{n}X_k-\mu \right| <\epsilon\right\} \geq 1-\frac{\frac{\sigma^2}{n}}{\epsilon^2}\end{eqnarray*}</script><p>when $n\to\infty$, then we can draw the conclusion.</p><h2 id="Bernoulli-LLN"><a href="#Bernoulli-LLN" class="headerlink" title="Bernoulli LLN"></a>Bernoulli LLN</h2><p>Assume that $f_A$ is the frequency of event $A$ happening in $n$ times independent repeated experiment,  and $p$ is the probability of event $A$ happening in each experiment, then for $\forall ~ \epsilon&gt; 0$</p><script type="math/tex; mode=display">\lim_{n \to \infty}P\left\{ \left| \frac{f_A}{n}-p \right| <\epsilon\right\} = 1</script><p>Proof:</p><p>From the Khinchin LLN</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Lemma-Chebyshev-Inequality&quot;&gt;&lt;a href=&quot;#Lemma-Chebyshev-Inequality&quot; class=&quot;headerlink&quot; title=&quot;Lemma: Chebyshev Inequality&quot;&gt;&lt;/a&gt;Lemma: 
      
    
    </summary>
    
      <category term="Mathematics" scheme="http://yoursite.com/categories/Mathematics/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/"/>
    
      <category term="Classic Statistics" scheme="http://yoursite.com/categories/Mathematics/Statistics/Classic-Statistics/"/>
    
    
      <category term="Probability" scheme="http://yoursite.com/tags/Probability/"/>
    
      <category term="Statistics" scheme="http://yoursite.com/tags/Statistics/"/>
    
      <category term="Stochastic" scheme="http://yoursite.com/tags/Stochastic/"/>
    
  </entry>
  
</feed>
